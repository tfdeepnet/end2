{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v7_Simple LSTMCell.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzlmnUwmDW-_"
      },
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltd8uj8o5-qw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "\n",
        "import os, pickle\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEOZp27rDeEm"
      },
      "source": [
        "### Upload the tweet csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4eAjHGbFON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c3e8a250-a3a0-4d3d-a45d-820f0caee819"
      },
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv( \"/content/tweets.csv\")  #\"/content/orig_swap_del_tlt_insDF.csv\") #   \"/content/tweets.csv\")\n",
        "df.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>@liberalminds Its trending idiot.. Did you loo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>RT @AstoldByBass: #KimKardashiansNextBoyfriend...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>RT @GatorNation41: gas was $1.92 when Obama to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>@xShwag haha i know im just so smart, i mean y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363</th>\n",
              "      <td>#OBAMA:  DICTATOR IN TRAINING.  If he passes t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweets  labels\n",
              "1359  @liberalminds Its trending idiot.. Did you loo...       0\n",
              "1360  RT @AstoldByBass: #KimKardashiansNextBoyfriend...       0\n",
              "1361  RT @GatorNation41: gas was $1.92 when Obama to...       1\n",
              "1362  @xShwag haha i know im just so smart, i mean y...       1\n",
              "1363  #OBAMA:  DICTATOR IN TRAINING.  If he passes t...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-ylf6C6BJD",
        "outputId": "3c8b7317-88d9-4fcc-84e6-8404fa33f4de"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxhrQox6Ju3",
        "outputId": "26fbc526-62fc-487b-ff0e-eb2256d68c53"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbqEGu8FDw4R"
      },
      "source": [
        "### Set a seed value to enable repeatibility of model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kqZx2hG6e4Q",
        "outputId": "5f851bb3-b70b-4c5b-eaec-5a64e6bf94e0"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb8c6ab9a30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQki6r1xEHn2"
      },
      "source": [
        "### Create Field and LabelField variables to hold the comment and label information\n",
        "\n",
        "**Field** - Defines a datatype together with instructions for converting to Tensor.\n",
        "\n",
        "Field class models common text processing datatypes that can be represented by tensors. It holds a Vocab object that defines the set of possible values for elements of the field and their corresponding numerical representations. The Field object also holds other parameters relating to how a datatype should be numericalized, such as a tokenization method and the kind of Tensor that should be produced.\n",
        "\n",
        "1.   The tweet will be stored in **Tweet** Field object\n",
        "2.   The label will be stored in **Label** LabelField object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mah6J3vsESsx"
      },
      "source": [
        "#### Map the 2 variables to column header \n",
        "\n",
        "| Column header | Variable name |\n",
        "| --- | --- |\n",
        "| **tweet** | Tweet |\n",
        "| **label** | Label |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK04HuwREqPW"
      },
      "source": [
        "### Create a list of example\n",
        "\n",
        "by doing list comprehension of the tweet and label dataframe generated from the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc9xHciZEyJu"
      },
      "source": [
        "### Create the Dataset \n",
        "\n",
        "by providing the above list of examples and the field mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rptONIZGBmm",
        "outputId": "2e3c663d-3bbd-4574-e202-f73bff400f3f"
      },
      "source": [
        "twitterDataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.legacy.data.dataset.Dataset at 0x7fb86ddc04d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ueqdslE3Me"
      },
      "source": [
        "### Split the dataset into\n",
        "\n",
        "train and validation in the ratio of **85:15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIA3n0l8m2x"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91fhtSKS8y3T",
        "outputId": "b752f954-50bc-4b26-f838-90e2eee2e16c"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wllgrWlVGhBw",
        "outputId": "dfc3985b-a444-4e01-fd84-53e202ea5e7e"
      },
      "source": [
        "train.fields"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': <torchtext.legacy.data.field.LabelField at 0x7fb86fe4d550>,\n",
              " 'tweet': <torchtext.legacy.data.field.Field at 0x7fb8c5761a10>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09AOF296E--e"
      },
      "source": [
        "### a training example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCDhbBKJ81ZK",
        "outputId": "6020d157-c142-465b-b7d0-8039d1067270"
      },
      "source": [
        "vars(train.examples[15])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0,\n",
              " 'tweet': ['In',\n",
              "  'his',\n",
              "  'teen',\n",
              "  'years',\n",
              "  ',',\n",
              "  'Obama',\n",
              "  'has',\n",
              "  'been',\n",
              "  'known',\n",
              "  'to',\n",
              "  'use',\n",
              "  'marijuana',\n",
              "  'and',\n",
              "  'cocaine',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPrsDbp8FEIW"
      },
      "source": [
        "A Vocab object defines the set of possible values for elements of the field and their corresponding numerical representations.\n",
        "\n",
        "Create Vocab object of the tweets and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "4995726f-e332-4ff6-c9a7-3e7149efe270"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBmMQQcX9SZk",
        "outputId": "e4700331-5047-416f-bddf-816d5b665dd3"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYkMaqCOFWCG"
      },
      "source": [
        "### Use the BucketIterator to split and create \n",
        "\n",
        "1.   train iterator\n",
        "2.   validation iterator\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "batch_size = 32\n",
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = batch_size, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mfSHuiZFd63"
      },
      "source": [
        "### Save the Vocab object for later use during testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT56G_9RFk8m"
      },
      "source": [
        "### Model class for training and validation\n",
        "\n",
        "The model has\n",
        "\n",
        "1.   An embedding layer which stores the list of words seen in the dataset and has weights attached to each word.These weights are adjusted during backpropagation to enable the model to converge at global minimum.\n",
        "\n",
        "2.   The model processes words in a sentence to encode the information ,\n",
        "\n",
        ">>   the sentences in the batch are padded with 0 to match the longest sentence in the batch.Here **nn.utils.rnn.pad_sequence** is used to pad the batch of sentences.\n",
        "\n",
        ">>   hidden state and cell state are initialized to 0 , before calling the encoder.\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "> *Step 1:* The word of the sentence is processed in left to right order. Each word is fed to a LSTMCell method , the hidden state returned is passed along with the next word.The hidden state is also stored in an array in the same order i.e from left to right.\n",
        "\n",
        "**Decoder**\n",
        "\n",
        "> *Step 2:* The hidden state from step 1 are vertically stacked and then reshaped to - sequence length x batch size x  embedded dimension.\n",
        "\n",
        ">> *Attention mechanism:* An attention mechanism is baked into the decoder\n",
        "\n",
        ">>> The last hidden state of the decoder is paired with each hidden state of the encoder.\n",
        "\n",
        ">>> Each pair is passed to a linear layer  to get the weight for that word\n",
        "\n",
        ">>> All the weights are then stacked vertically and reshaped to get the relative weight of each word w.r.t the sentence using a softmax function.\n",
        "\n",
        ">>> The relative weight vector is multiplied with the singlevector generated by the encoder to get the **Context vector** of the word w.r.t the sentence.\n",
        "\n",
        "> The context vector of the word and the last hidden state of the decoder is fed to  LSTMCell in a loop.\n",
        "\n",
        "3.   Output of the decoder is fed to a linear layer to return 3 class values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTxS2HF4dJu4"
      },
      "source": [
        "### A global flag is used to check whether to print the encoder and decoder output at each step\n",
        "\n",
        "*   printEncoderDecoderOutput \n",
        "\n",
        "This flag is false during training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQnNcH6-oZZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "printEncoderDecoderOutput = False\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()  \n",
        "        ## store the hidden state   \n",
        "        self.hidden_dim = hidden_dim     \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        \n",
        "        # LSTMCell layer for processing words from left to right\n",
        "        self.encoder_fwd = nn.LSTMCell(hidden_dim, \n",
        "                           hidden_dim)\n",
        "\n",
        "        # LSTMCell layer to process the hidden state returned by the encoder.\n",
        "        self.decoder = nn.LSTMCell(hidden_dim, \n",
        "                           hidden_dim)\n",
        "\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.attentionfc = nn.Linear(hidden_dim*2, 1)\n",
        "\n",
        "    def attention(self, decoderhidden, singlevector,batchsize, seqlen):\n",
        "\n",
        "        #print('atn sv',singlevector.size())\n",
        "        attention = []\n",
        "        for i in range(seqlen):\n",
        "\n",
        "          attentionhidden = torch.cat((decoderhidden,singlevector[i]),1)\n",
        "          #attentionhidden = attentionhidden.to(device)\n",
        "          #print(attentionhidden.size())\n",
        "          attentionout = self.attentionfc(attentionhidden)\n",
        "          attention.append(attentionout)\n",
        "          \n",
        "        tup_attention = tuple(a for a in attention)\n",
        "        attentionvstack = torch.vstack(tup_attention)\n",
        "        attentionvector = attentionvstack.reshape(batchsize, seqlen)\n",
        "        attentionvector = attentionvector.unsqueeze(1)\n",
        "\n",
        "        alpha = F.softmax(attentionvector , dim=1)\n",
        "        \n",
        "        reshapedsinglevector = singlevector.reshape(batchsize, seqlen , self.hidden_dim)\n",
        "        #print('alp',alpha.size() , reshapedsinglevector.size())\n",
        "        \n",
        "        context = torch.bmm(alpha,reshapedsinglevector)\n",
        "\n",
        "        context = context.squeeze(1)\n",
        "\n",
        "        return context\n",
        "          \n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        global printEncoderDecoderOutput\n",
        "\n",
        "        # Initialization of hidden state and cell state for LSTMCell\n",
        "        hidden_fwd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "        cell_fwd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "\n",
        "        # Weights initialization\n",
        "        torch.nn.init.xavier_normal_(hidden_fwd)\n",
        "        torch.nn.init.xavier_normal_(cell_fwd)\n",
        "        #print(text_lengths)\n",
        "\n",
        "        hidden_fwd , cell_fwd = hidden_fwd.to(device) , cell_fwd.to(device) \n",
        "        \n",
        "\n",
        "        # Initialization of hidden state and cell state for decoder LSTMCell\n",
        "        hidden_dcd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "        cell_dcd = torch.zeros(text.size(0), self.hidden_dim)\n",
        "\n",
        "        # Weights initialization\n",
        "        torch.nn.init.xavier_normal_(hidden_dcd)\n",
        "        torch.nn.init.xavier_normal_(cell_dcd)\n",
        "        #print(text_lengths)\n",
        "\n",
        "        hidden_dcd , cell_dcd = hidden_dcd.to(device) , cell_dcd.to(device) \n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "\n",
        "        # padding the batch\n",
        "        packed_embedded = nn.utils.rnn.pad_sequence(embedded, batch_first=True)\n",
        "\n",
        "        # shuffle the packed embedded tensor to bring the 2nd dim to 1st dim , this dim holds the padded string string length.\n",
        "        # We will iterate through this tensor to fetch the words from left to right.\n",
        "        packed_embedded = packed_embedded.view(packed_embedded.data.size(1), text.size(0), -1)\n",
        "        \n",
        "        bsize = packed_embedded.data.size()[1]\n",
        "        seq_len = packed_embedded.data.size(0)\n",
        "\n",
        "        ## Encoder block\n",
        "        hiddenFwdList = []\n",
        "        for i in range(packed_embedded.data.size(0)):  \n",
        "          \n",
        "          hidden_fwd, cell_fwd = self.encoder_fwd(packed_embedded[i] , (hidden_fwd, cell_fwd))\n",
        "          # save the hidden state in a list for use during decode\n",
        "          hiddenFwdList.append(hidden_fwd)\n",
        "          \n",
        "          if printEncoderDecoderOutput:\n",
        "            print('encdr word ', i ,hidden_fwd.size(),hidden_fwd)\n",
        "\n",
        "\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # create a tuple of all the hidden state from left to right\n",
        "        tup_hidden = tuple(h for h in hiddenFwdList)\n",
        "\n",
        "        # vertically stack the hidden state \n",
        "        vstack_hidden = torch.vstack(tup_hidden)\n",
        "        \n",
        "        # reshape the vertically stacked tensor to shape - batch size x seq_len x hidden dimension\n",
        "        singlehiddenvector = vstack_hidden.reshape( seq_len , bsize , -1 )\n",
        "\n",
        "        ## decode block\n",
        "        # loop through each hidden state of the encoder along with previous hidden state of decoder\n",
        "        #print('pkd ',packed_embedded[1].size())\n",
        "        for i in range(packed_embedded.data.size(0)):  \n",
        "          contextvector = self.attention(hidden_dcd, singlehiddenvector, bsize, seq_len)\n",
        "          #print(contextvector)\n",
        "          hidden_dcd, cell_dcd = self.decoder(contextvector , (hidden_dcd, cell_dcd))\n",
        "          \n",
        "          if printEncoderDecoderOutput:\n",
        "            print('decd word ', i ,hidden_dcd.size(),hidden_dcd)\n",
        "          \n",
        "        \n",
        "        dense_outputs = self.fc(hidden_dcd)\n",
        "        #print(dense_outputs)\n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs, dim=1)\n",
        "        #print(output)\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1YPR0X0VoG9"
      },
      "source": [
        "### Set the hyperparameters before running the model\n",
        "\n",
        "1.   dropout\n",
        "2.   number of nodes in embedding layer\n",
        "3.   number of nodes in hidden layer\n",
        "4.   number of layers in LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRextCcAASGO",
        "outputId": "214e90b7-450f-46dd-cc81-91ae147d6f7c"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 100)\n",
            "  (encoder_fwd): LSTMCell(100, 100)\n",
            "  (decoder): LSTMCell(100, 100)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            "  (attentionfc): Linear(in_features=200, out_features=1, bias=True)\n",
            ")\n",
            "The model has 627,204 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3rz1d_VV6Dh"
      },
      "source": [
        "### A utility function to calculate the model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "learning_rate = 2e-1\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sth9nOW6WIrh"
      },
      "source": [
        "### wrapper function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet \n",
        "        tweet, tweet_lengths = tweet.to(device), tweet_lengths.to(device) \n",
        "        #print(tweet_lengths)\n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        #print(predictions.shape, len(batch.label))\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ektXSpEmWKai"
      },
      "source": [
        "### wrapper function to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            if (len(predictions.size())<2):\n",
        "              predictions = predictions.unsqueeze(0)\n",
        "\n",
        "            #print(tweet_lengths , predictions.size(), batch.label.size())\n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSaQQNe5WT1x"
      },
      "source": [
        "### Run the model over few epochs to see the model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7UPwN0KAvVq",
        "outputId": "e12ac6f1-f32e-4ec0-cf52-a484a9df1d4c"
      },
      "source": [
        "\n",
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "trainLossList = []\n",
        "valLossList = []\n",
        "\n",
        "trainAccyList = []\n",
        "valAccyList = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    trainLossList.append(round(train_loss,2))\n",
        "    valLossList.append(round(valid_loss,2))\n",
        "\n",
        "    trainAccyList.append(round(train_acc,2))\n",
        "    valAccyList.append(round(valid_acc,2))\n",
        "\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.873 | Train Acc: 66.93%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.860 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.868 |  Val. Acc: 68.30% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kaT0i4UWfIK"
      },
      "source": [
        "### A graph of model performance \n",
        "\n",
        "1.   Training and validation accuracy across different epochs\n",
        "2.   Training and validation loss across different epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "Wl132D123vmo",
        "outputId": "6efb0f03-60b1-44b8-d9df-89dedcb8ef5c"
      },
      "source": [
        "xpoints = np.arange(len(trainLossList))\n",
        "ypoints4 = trainAccyList\n",
        "ypoints6 = valAccyList\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 8]\n",
        "plt.plot(xpoints, ypoints4, label = \"$ Training Accuracy $\" )\n",
        "plt.plot(xpoints, ypoints6, label = \"$ Validation Accuracy $\" )\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"model performance\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy \")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAHyCAYAAABiaFOXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxcdZ3v/9eHJBA2CSZhkZB0MwZJIBAkYggIiOLADC4MyMDFbX6j8HPAWZjrdZlcFGa4LtfRqyM4FxVxQUVBmYAQVEQBESGs2dhMV0tAhK4EMN3Z87l/1Omm0nST6qQr3dX1ej4e9UjVt751zvdUhUfefM/5fk5kJpIkSWpcOwz1ACRJkrRtDHSSJEkNzkAnSZLU4Ax0kiRJDc5AJ0mS1OAMdJIkSQ3OQCdpyERES0Rk8fjlVm7jyqpttAzqAAdRROwdEVdFxB8iYmMx3v8z1OOSNDKMHuoBSFKT+CLw10M9CEkjk4FOkuooIsZm5hrgiKLpOaA1M5+r034kNSFPuUpNqtepylMj4jsR8afilODHo+JvIuKxov2XETG91zZGR8Q/RcR9EdEZEWsiYklEXBwRu/bq+4qI+FpErIyIFyLie8DeLzO+aRHx7Yh4MiLWRcQzEXFNRBy6Dcf8yapjfntE/N+IeDYiuiJifkS8plf/HSLivIi4JyJWRcTqiFgYEf89IkZX9as+dXxlRJwTEQ9HxHrgzIhI4NVF93HAyqLv+4rP7xoRF0XE4mIfXRFxf0RcMMD9bHYKOyJOK95fHRG/ioiDImLfiLi2OJ72iLgwInao2sebIuKGiCgVfdZFxBPF34/uY+ju+8uq/R0UEfOKvytPF7/1K3r13734u7GwOMbO4pj/R69+J0XEzRGxoth/KSL+IyImbO1vL414menDh48mfABXAlk8nq163v34rz7aHgdGF58fBdzYR5/ux73ArkXfAH7RR5+nqp7/smpsxwBd/Wx3NfCGfo6jZQvH/MktHPMfgX2KvjsA173M8V0PRNG3paq9o1e/973MNt4H7Fp8V/31uRHYocb9VL+/AtjYx++3qI99/H9V39FHX2YsfwQmVPX9ZdV7K/vo/7WqvhOAh/vZbvVv/88vs/9lwF5D/d+ODx/D8eEMnSSAp4HJwKlVbW8DLqEyo/Tjou3PgNcXz88ETi6e31+8tw9wc9H2WuAfiudvAd5YPH8cOAjYF3isn/F8FdgZaKdyqnIn4HAqIWwscOkAj68vK4GDqQSNa4u2vYDu2aIzgLcXzz8FvBJ4BdC9kOEUNv++uo0HPl1sdy/gp5kZxbEAtGdmFI8rgX+k8l1B5bvbFzgAuK9oO5nKd73F/fR6f0/g76n8fr8p2v6seD2Nyu/YfTPvs6o+9zPgWCqzp2OK476keG8v4F19jAXg7mLsrwfWFm1nR0QUzy8GumdA7wBmUAmzs4AfAkTE/lS+a4D5wBQqv3f38bcCc/vZv9TchjpR+vDhY2gebD6z9f6ibeeqtnXAzkX7OVXtZxVt361qO7Vqu4dVtd9RtH2mqu3vq/q+iV6zNMBU+p+hqX7s08dxtGzhmD9Z1fcDVe3V+1xYtF1Vwxj+s+jbUtX2MMXMXa99l4r3S73a76z67OFV7W+vav9OLfvp9f4TVe3V3/+/VrV3z5A+UtW2D3AZleC9po9j/kpV319WtR9S1b6gj99peVXblH5+nw/U8J0/PNT/7fjwMRwfLoqQBJWwQWaufnFChWcyc3XxfF1V352KPydWtf2+6nl71fO9ij/HV7Ut7+d5789syXgqM4tb6/f9PO++TquWcYzvo+3BzMw+2vszkO9xIPup/vzqftq7f9edoHLNIHALsNm1kr3s3E/7I1XPO6uejy3+7L5esiszq8dQbWu/c6npecpVEsCGGtuqPVP1fHI/z7v7dFS1TerneV/b/Xm+eHqy50HlmrLFWxjflvQ35u6xVo/jmH7GcUYf213dR9vLGcj3OJD99Pf7vdzveigvhrnFVGb8dqBy+v1lZeb66pd9dPlj8ecuETG5j/dh8+Oc2893Xmvgl5qKgU7S1vpJ1fN/iYjWiNibynVdvfvcWtV2fkS8JiL2Af5n741m5mPAo8XLN0XEP0bEuIgYGxGHRcSFwPcHYfz/XKzMHM+L121B5RoygBuq2r5Y7HvHqBQIPjUibqByrdm2qv4eLym23wJc2E+feqoOe2uBVVSC5ccGYdvzqp5/KyIOjoidi+/174r2m6vG8M/FatddorJC+riI+E/gI4MwFmnEMdBJ2lpXAzcVz4+gsgLxaV5cKHEf8KXi+U+pXG8FlevVHgb+QGVRQl/OoXL9VgBfoLKAYTXwAHARL1PuZAB2B5ZSmZE7rWh7Bvhs8fxqXgxSRxT7XkvlGH8E/GUxvm31RTZfAPE00MaLdetuKsayPTxM5TuBykKNDiqn4wejXMiFvHha9jgqq227qHyvZwBk5u+Bfyn67Enl2DuB56n8/TmXF0/hSqpioJO0VTJzI5VTcf9MZZVrF5XAsxT4V+DYzOws+ibwDuAKKv84r6ISivpaJUpm/opKoPkWlevs1lMpw/EQ8B/AxwfhEM6lcvF/B5Xw+NNizE8XY9hEZWHC+cBvizGvpXIN2vyi/b6XbnZgiu/oWCqrQJcW+1hDJej8M/C2Yix1l5kbqPymNwF/ovLdfInKatlt3XYHcCSVvxuLqRxjF5VjvrGq32eBvyjGUKYyY/c0lcUjnwC+ua1jkUai7hpKkjTiRcQnqYQCgDdm5i+HbjSSNHicoZMkSWpwBjpJkqQG5ylXSZKkBucMnSRJUoMz0EmSJDW4pr7114QJE7KlpWWohyFJkrRF9957b0dmTuzrvaYOdC0tLSxYsGCohyFJkrRFEdHffZA95SpJktToDHSSJEkNzkAnSZLU4Jr6GjpJkoba+vXrWb58OWvWrBnqoWiYGDt2LJMmTWLMmDE1f8ZAJ0nSEFq+fDm77747LS0tRMRQD0dDLDMpl8ssX76c1tbWmj/nKVdJkobQmjVrGD9+vGFOAEQE48ePH/CMrYFOkqQhZphTta35+2CgkyRJanAGOkmSpAZnoJMkqcl97WtfY+bMmcycOZMddtih5/k//dM/1byNO++8kwsvvHCb+2zJhz70IaZMmbJN2xiJIjOHegxDZtasWemtvyRJQ2np0qVMmzZtqIcBwJNPPsmcOXNob+/7DlMbN25k1KhR23lULyqVSpxyyimUy2UeffRRdt9997rta6iPta+/FxFxb2bO6qu/M3SSJAmARYsWMWPGjM3a3vnOd3Luuecye/ZsPvWpT3HNNdcwe/ZsDjvsMI455hieffbZnn633347AH/1V3/F3LlzOfbYY5k8eTI///nPa+6zdOlSjj32WA499FD+9//+37z61a/uGcsnPvEJ5s6dy/Tp01m8eHFP+1NPPcVpp53G4YcfzkEHHcTdd9/db/tRRx1FW1sbUAmwRxxxxICPtfd2b7vtNubMmdOznfvuu483velNg/CL1M46dJIkDRMXXb+YJU+9MKjbnP6qV/CJtx5cU9+FCxdyyCGHvKTtjDPO4K677gKgXC5z+umnV8Z70UX84Ac/4LzzzmPRokUceuihPZ+ZM2cOt912Gz/+8Y+56qqrePOb37zFPscffzxnn302X//61zn88MP54Ac/2DOexYsXs2jRIq688kruuOMOFi1axOzZs9mwYQMnn3wyl1xyCaeccgpdXV1s3Lixz/b169fT3t5OS0sLAA899FDPeGo91nPPPbfP7S5btqxnVu+CCy7g85///Nb8XFvNQCdJkoDKDN2JJ57Y83rNmjWsWLFis+verrzySq6++mrWrl3L008/zf/6X/+LNWvWsG7dOvbYYw+6urp4/vnne66/W79+PePGjaupz49+9CMOO+wwDj/8cACmT5/OXnvtBcDcuXO5+OKLiQimTZvWM0N33XXXMW3aNE455RQAdtllFwCuueaal7Q/9thjtLa29pQFeeihh3pmJGs91v72d/DBB7N48WIee+wxpkyZwmtf+9pB+11qUddAFxEnAV8ERgFfy8xP99HnDOCTQAIPZuZ/K9o/A/xl0e1fM/Pqor0V+D4wHrgXeHdmrouInYBvAUcAZeCvM7NUv6OTJGlw1TqTVi8LFy7cbCHE4sWLef3rX8/o0ZW48K1vfYu7776bX/ziF+y2224ce+yxPUFm+vTpACxZsoQjjjii5/qzhx56iEMOOaSmPg899BAzZ87s2f+iRYs46aST+O1vf8v8+fO5//77Oe+881izZk1PEHvggQeYPXv2S46lr/aFCxdudkp5wYIFnHPOOQM61htuuKHP/c2ePZtf//rXXHbZZcyfP38gX/ugqNs1dBExCrgUOBmYDpwVEdN79ZkKfAw4OjMPBv6xaP9L4LXATOD1wH+PiFcUH/sM8IXMfDWwEvjbov1vgZVF+xeKfpIkqQabNm3iscce2+xC/IULF77klOScOXPYbbfduPbaa7nzzjuZMWPGZv0WLly4WSjrPq1ZS5/x48fz6KOPApVA9p3vfIfDDjuMj3/841x//fWUSiVKpRIPPvhgzwzdPvvss9n1dN3XufXVvmLFCsaNGwdUrtX7yU9+stmYajnW/vY3e/Zs5s6dy6mnnsp+++038B9gG9Vzhu5I4PHMXAYQEd8H3g4sqerzAeDSzFwJkJnPFO3TgdsycwOwISIeAk6KiB8CJwD/rej3TSqze18ptv3Jov0a4MsREdnMy3i3g42bklVrNwz1MCSpYW3KZMOmTUM9DB599FEmTZrEDqNH94znwYce4nWve13P63e95z2ccfrpfOeqqzjxxBM54IAD2GnnnTfr9+BDD3HkkUf2fGbRokUcNH063/3e97bYZ/8pU3jbW9/KITNmcNxxx9HS0sJjjz/O2nXrOP6EE3r6j584kVWrVvFMRwfves97uPnsszn44IMZPWYMn/zkJ3nr297WZ/ubTjyR//jyl2n//e95zWtew/jx4xk/cWLPmGo51v72d+CBr2GnnXbiIx/5yPb+6YA6li2JiNOBkzLz/cXrdwOvz8zzq/pcBzwKHE3ltOwnM3N+RLwF+ARwIrALcDeV2b5vAncVs3BExP7ATZl5SEQsKva3vHjvd8X+Ovobo2VLtt27v/5bbn+s369YkrQFX33bvuw9+YChHsaw0NW5il123Q2AK//zS6x64QXO/x9zh3hUtfn8RR/ljcccxXvf+95B2d5Ay5YM9aKI0cBU4HhgEnBbRMzIzJ9GxOuAO4Fngd8AGwdjhxFxDnAOwOTJkwdjk00rM7mvfSVHHTCeN0/fe6iHI0kNadzOq9h3j52HehjDwr//5xe47tofMnrMGI58/VFc/KnPstNOOw31sF5W27LfcfY7T+WoOXMGLcxtjXoGuieB/ateTyraqi0HfpuZ64G2iHiUSsC7JzMvAS4BiIjvUpnJKwPjImJ0cTq2epvd+1seEaOBPYr+m8nMy4HLoTJDNxgH2qyeXbWWznUb+fOD9+Z9R7cO9XAkqSEtXbqUibsP79CyvXz63y7i0/920VAPY0AmHjadxx59ZKiHUdfCwvcAUyOiNSJ2BM4E5vXqcx2V2TkiYgJwILAsIkZFxPii/VDgUOCnxfVwtwKnF59/L/BfxfN5xWuK93/h9XP11V7uAqBlwq5DPBJJkppb3WboMnNDRJwP3Ezl+rgrMnNxRFwMLMjMecV7b4mIJVROqX44M8sRMRa4vagT8wLwrmJGDuAjwPcj4t+A+4GvF+1fB74dEY8DK6gESNVRW0cnAC3jDXSSJA2lul5Dl5k3Ajf2aruw6nkCFxSP6j5rqKx07Wuby6isoO3dvgZ457aPWrVqL3cyeodg0p5e+yFJ0lDyXq7aaqWOLibtuTOjR/nXSJKkoeS/xNpqpXKn189JkjQMGOi0VTKTUken189JkjQMGOi0VTpWraNz3UZaxu8y1EORJKnpGei0VUrlygrXKZ5ylSRpyBnotFVKRcmSVk+5SlLD+93vfseMGTM2a1u7di2tra2b3Yi+2i233MK73vUuAO68804uvPDCPvu9//3v54YbbnjZ/S9fvpyrr756i9saiA996ENMmTJlm7fTKAx02iqlciejdgj2s2SJJDW81tZWli9fzqbixvQAl19+OcceeywHH3xwn5958MEHmTlzJgBz5szh4osv7rPf/fff39OvP7fccgv33XffFrdVq1KpxK233sq6dev405/+tE3bejkbNw7KXUkHhYFOW6VU7mL/PXdmjCVLJKnh7bDDDkyePJlSqQTA6tWr+fd//3cuuugirrnmGmbPns1hhx3GMcccw7PPPgtUAt1hhx0GwDvf+U5uv/12AB599FGOOeYYZsyYwSWXXMLTTz/NpEmT+t3OHXfcwQUXXMA111zDzJkzN9vWww8/zAknnMDMmTN585vfTEdHBwB/9Vd/xdy5czn22GOZPHkyP//5zzc7nk984hPMnTuX6dOn98wwPvXUU5x22mkcfvjhHHTQQdx99939th911FG0tbUB8OSTT3LEEUf0bPud73wn5557LrNnz+ZTn/pUv8fV13YXLVrEnDlzerZ133338aY3vWlQfsO6FhbWyFXq6GSKp1slaXDd9FF4euHgbnOfGXDyp7fYbdq0aTz88MMccMABXHrppbz1rW+lpaWF3XffndNPr9xx86KLLuIHP/gB5513Hg8++CCf+9znAFi0aBGHHnooa9eu5dRTT+Ub3/gGRx55JH/3d3/HQQcdBMAb3/jGPrdzzDHH8LrXvY7Pfe5zHHLIIUybNq1nW6eddhpXXXUVM2fO5DOf+Qxf+MIXuOSSS1i4cCFz5szhtttu48c//jFXXXUVb37zmwFYvHgxixYt4sorr+SOO+5g0aJFzJo1i5NPPplLLrmEU045ha6uLjZu3MiGDRte0r5+/Xra29tpaWkB4KGHHuLQQw/t+Z4WLlzIGWecwV133QVAuVx+yXGde+65fe5v1113ZdmyZWzcuJFRo0ZxwQUX8PnPf34QfmRn6LQVMpP2chetLoiQpBFj2rRpPPLII6xatYovf/nLzJ07F4Arr7ySI488ksMOO4zLLruMsWPHsn79ep5//nkmTpzImjVrWLduHXvssQfXXXcds2bN4sgjKzd0Ovjgg3tm8fraTrdHHnmEgw466CXbOuaYY3pO106fPp1nnnmGrq4unn/+ef7pn/4JgPXr1zNu3Liebc2dO5eLL76YiGDatGksXryY6667jmnTpnHKKacAsMsuu7D77rv32f7MM8/Q2tpKcftRHnrooZ7rC9esWcOKFSs2u8avr+Pqb3877LADBx98MIsXL+baa69lypQpvPa1rx2U388ZOg1Yx6p1rFq7gSmWLJGkwVXDTFq9TJs2jVtuuYUvfvGLnH322ey9995861vf4u677+YXv/gFu+22W881dUuXLmXatGlAZUZs+vTK3ToXLly42enJe++9l+OPP77f7QB0dHSwxx57MHr0aB588MGebS1ZsmSzhRoLFy5k+vTpLFmyhCOOOIJRo0YBlcB1yCGHAPDb3/6W+fPnc//993PeeeexZs0aZsyYwa677srs2bNfcswPPPDAS9oXLly42X4XLFjAOeec03Osr3/96xk9uhKf+juuG264oc/9AcyePZtf//rXXHbZZcyfP7/Wn2eLnKHTgLUXJUu8S4QkjRzTpk3j7rvv5oorruDDH/4wQM+pzd12241rr72WO++8kxkzZmx2/dzChQt7TkmOHz+eRYsWAZUw973vfY/DDjus3+1AZQHDq171qpdsa7/99mPJkiUALFu2jG9/+9u85z3vYeHChZstsqg+Jfrxj3+c66+/nlKpRKlU4sEHH2Tx4sXss88+m63W7b7Ora/2FStW9Mz4LV26lJ/85Cc9268e38t9P/3tDyqBbu7cuZx66qnst99+W/NT9clApwFrK0qWeJcISRo5DjzwQBYuXMg555zTE2je9773cdlll3HkkUdy//33c8ABB7DrrrtutsK1OuS8+93v5oEHHmDmzJl89rOfZdy4cUyfPr3f7QAcdNBBdHR0cMghh/DNb35zs2099dRTzJgxgzPPPJMrrriC8ePHvyTQLVq0iEMOOYSf//znrFu3rudaOoC9996bVatW8ba3vY0//vGPHHzwwcycOZPf/OY3PcfXu/3P//zPmT9/PmeffTY//OEPGT9+PHvvvfdLjvXlvp++ttvtoIMOYqedduIjH/nIoP5+kZmDusFGMmvWrFywYMFQD6PhfO7mR/jKr37Hw/96kqtcJWkbVZ++1Mh3/vnn87rXvY73vve9L9uvr78XEXFvZs7qq7//GmvA2sqdTLJkiSRJNfvd737HQQcdxOrVq7cY5raGiyI0YO1lS5ZIkjQQf/Znf8bDDz9ct+07xaIByUxKHV20usJVkqRhw0CnASl3dpcscYZOkqThwkCnASkVK1wtKixJ0vBhoNOAlMpdABYVlqRB1MwVJ/RSW/P3wUCnASl1dDJqh2DSngY6SRoMY8eOpVwuG+oEVMJcuVze7NZotXCVqwakVO5kv3E7s+No/19AkgbDpEmTWL58+WZ3E1BzGzt2LJMmTRrQZwx0GpBSudNbfknSIBozZgytra1DPQw1OKdZVLPMpL2jixavn5MkaVgx0Klm5c51/GntBu/hKknSMGOgU83ay5WSJS0TnKGTJGk4MdCpZm0dlZIlztBJkjS8GOhUs/ZyJzsEliyRJGmYMdCpZm0dnUzacxdLlkiSNMz4L7Nq1l7u8g4RkiQNQwY61SQzKXV0eg9XSZKGIQOdarKiKFkyxQURkiQNOwY61aRUlCxptWSJJEnDjoFONSkVJUucoZMkafgx0KkmpaJkyf6WLJEkadgx0KkmpXIX++25syVLJEkahvzXWTUpdXR6hwhJkoYpA522KDMplQ10kiQNVwY6bdGKznX8ac0GWqxBJ0nSsGSg0xaVypUVri3eJUKSpGGproEuIk6KiEci4vGI+Gg/fc6IiCURsTgivlvV/tmibWlEfCkqdo+IB6oeHRHxf4r+74uIZ6vee389j62ZlDoqNeicoZMkaXgaXa8NR8Qo4FLgRGA5cE9EzMvMJVV9pgIfA47OzJURsVfRPgc4Gji06HoHcFxm/hKYWfX5e4EfVe326sw8v17H1KzaLVkiSdKwVs8ZuiOBxzNzWWauA74PvL1Xnw8Al2bmSoDMfKZoT2AssCOwEzAG+GP1ByPiQGAv4Pa6HYEAaLNkiSRJw1o9/4XeD3ii6vXyoq3agcCBEfHriLgrIk4CyMzfALcCfygeN2fm0l6fPZPKjFxWtZ0WEQ9FxDURsf9gHkwza3eFqyRJw9pQT7mMBqYCxwNnAV+NiHER8WpgGjCJSgg8ISLe0OuzZwLfq3p9PdCSmYcCPwO+2dcOI+KciFgQEQueffbZQT2YkSgzabMGnSRJw1o9A92TQPUs2aSirdpyYF5mrs/MNuBRKgHvVOCuzFyVmauAm4Cjuj8UEYcBozPz3u62zCxn5tri5deAI/oaVGZenpmzMnPWxIkTt+0Im8DKrvX8ac0GprjCVZKkYauege4eYGpEtEbEjlRm1Ob16nMdldk5ImIClVOwy4DfA8dFxOiIGAMcB1Sfcj2LzWfniIh9q16+rVd/baW2YoVrqytcJUkatuq2yjUzN0TE+cDNwCjgisxcHBEXAwsyc17x3lsiYgmwEfhwZpYj4hrgBGAhlQUS8zPz+qrNnwH8Ra9d/n1EvA3YAKwA3levY2sm7eVKoJviKVdJkoatugU6gMy8EbixV9uFVc8TuKB4VPfZCJz7Mts9oI+2j1EpgaJBVOooSpa8cuehHookSerHUC+K0DBXKnfxqnE7s9PoUUM9FEmS1A8DnV5Wqdzp9XOSJA1zBjr1q7tkiStcJUka3gx06ld3yRJr0EmSNLwZ6NSvUrHC1UAnSdLwZqBTv0pFDboWr6GTJGlYM9CpX6VylyVLJElqAAY69avU0WnJEkmSGoCBTv1qL3d6/ZwkSQ3AQKc+dZcsaZlgyRJJkoY7A5369FzXel6wZIkkSQ3BQKc+tVmyRJKkhmGgU5/auwOdp1wlSRr2DHTqU1tHFxGw/ysNdJIkDXcGOvWpvdzJq/awZIkkSY3AQKc+lTo6afUOEZIkNQQDnfpUKncxZbynWyVJagQGOr3Eys51PL96vTN0kiQ1CAOdXqJUrHCdYskSSZIagoFOL9Ed6FotWSJJUkMw0OklSkXJkkl7GugkSWoEBjq9RKkoWTJ2jCVLJElqBAY6vUSp3OUdIiRJaiAGOr1EqaPTe7hKktRADHTazHNdlZIlBjpJkhqHgU6baeuorHBtsQadJEkNw0CnzbSXuwBo8S4RkiQ1DAOdNtPW0UkE7P9KA50kSY3CQKfNtFuyRJKkhmOg02baLFkiSVLDMdBpM+3lTu/hKklSgzHQqcdzXet4rms9rQY6SZIaioFOPUrFCtcprnCVJKmhGOjUo1TUoGu1Bp0kSQ3FQKcepbIlSyRJakQGOvVoL3dZskSSpAZkoFOPto5Or5+TJKkBGejUo73c6T1cJUlqQAY6AfB813pWdq33Hq6SJDUgA52AyoIIgBZr0EmS1HAMdAKqAp2nXCVJajh1DXQRcVJEPBIRj0fER/vpc0ZELImIxRHx3ar2zxZtSyPiSxERRfsvi20+UDz2Ktp3ioiri339NiJa6nlsI02po4sImGzJEkmSGs7oem04IkYBlwInAsuBeyJiXmYuqeozFfgYcHRmrqwKZ3OAo4FDi653AMcBvyxen52ZC3rt8m+BlZn56og4E/gM8Nd1ObgRqFTuZN9XjLVkiSRJDaieM3RHAo9n5rLMXAd8H3h7rz4fAC7NzJUAmflM0Z7AWGBHYCdgDPDHLezv7cA3i+fXAG/qntXTlpVc4SpJUsOqZ6DbD3ii6vXyoq3agcCBEfHriLgrIk4CyMzfALcCfygeN2fm0qrPfaM43fo/q0Jbz/4ycwPwPDB+sA9qpCp1dDLFBRGSJDWkoV4UMRqYChwPnAV8NSLGRcSrgWnAJCpB7YSIeEPxmbMzcwbwhuLx7oHsMCLOiYgFEbHg2WefHSNdG8EAACAASURBVKTDaGzdJUtaJ3j9nCRJjaiege5JYP+q15OKtmrLgXmZuT4z24BHqQS8U4G7MnNVZq4CbgKOAsjMJ4s//wR8l8qp3c32FxGjgT2Acu9BZeblmTkrM2dNnDhxUA600XWvcHWGTpKkxlTPQHcPMDUiWiNiR+BMYF6vPtdRmZ0jIiZQOQW7DPg9cFxEjI6IMVQWRCwtXk8o+o8BTgEWFduaB7y3eH468IvMzHod3EjSHehavYZOkqSGVLdVrpm5ISLOB24GRgFXZObiiLgYWJCZ84r33hIRS4CNwIczsxwR1wAnAAupLJCYn5nXR8SuwM1FmBsF/Bz4arHLrwPfjojHgRVUAqRqUOroAixZIklSo6pboAPIzBuBG3u1XVj1PIELikd1n43AuX1srxM4op99rQHeue2jbj7t5U5etYclSyRJalRDvShCw0Bb2RWukiQ1MgOdaC93WYNOkqQGZqBrcs+vXs+KznW0jPf6OUmSGpWBrsm1FytcnaGTJKlxGeiaXFtHEei8hk6SpIZloGty7eVKyZIpnnKVJKlhGeiaXKmjk30tWSJJUkMz0DW5UrnT062SJDU4A12TK5W7aJng6VZJkhqZga6JvViyxBk6SZIamYGuiXWXLPEuEZIkNTYDXRMrFStcW61BJ0lSQzPQNbFSUYNu8iu9hk6SpEZmoGtipXKlZMnOO1qyRJKkRmaga2Kljk4LCkuSNAIY6JpYe7nL6+ckSRoBDHRN6oU16yl3rnOFqyRJI4CBrkm1d1RWuFqDTpKkxmega1JtRQ067xIhSVLjM9A1qfaiZMmUVzpDJ0lSozPQNam2cif7vMKSJZIkjQQGuibVXu7ydKskSSOEga5JlTo6XRAhSdIIYaBrQt0lS1qsQSdJ0ohgoGtCL5Ys8ZSrJEkjgYGuCZV6SpY4QydJ0khgoGtCJUuWSJI0ohjomlCp3GXJEkmSRhADXRMqlTuZ4vVzkiSNGAa6JtRe7qTV6+ckSRoxDHRN5k9r1tOxah1TrEEnSdKIYaBrMu3lSsmSVu8SIUnSiGGgazJt3StcnaGTJGnEMNA1mfZyd6Bzhk6SpJHCQNdk2jq62PsVO7HLjqOHeiiSJGmQGOiaTHu5kxZPt0qSNKIY6JpMyUAnSdKIY6BrIt0lS7yHqyRJI4uBrol0lyxpcUGEJEkjioGuiZSKFa7O0EmSNLLUNdBFxEkR8UhEPB4RH+2nzxkRsSQiFkfEd6vaP1u0LY2IL0XFLhHxk4h4uHjv01X93xcRz0bEA8Xj/fU8tkZU6rBkiSRJI1HdaldExCjgUuBEYDlwT0TMy8wlVX2mAh8Djs7MlRGxV9E+BzgaOLToegdwHHA38LnMvDUidgRuiYiTM/Omot/VmXl+vY6p0ZXKliyRJGkkqucM3ZHA45m5LDPXAd8H3t6rzweASzNzJUBmPlO0JzAW2BHYCRgD/DEzuzLz1qLvOuA+YFIdj2FEKXV0eocISZJGoHoGuv2AJ6peLy/aqh0IHBgRv46IuyLiJIDM/A1wK/CH4nFzZi6t/mBEjAPeCtxS1XxaRDwUEddExP6DeziNr1TuotVAJ0nSiDPUiyJGA1OB44GzgK9GxLiIeDUwjcrs237ACRHxhu4PRcRo4HvAlzJzWdF8PdCSmYcCPwO+2dcOI+KciFgQEQueffbZOh3W8FMpWbKWKRO8fk6SpJGmnoHuSaB6lmxS0VZtOTAvM9dnZhvwKJWAdypwV2auysxVwE3AUVWfuxx4LDP/T3dDZpYzc23x8mvAEX0NKjMvz8xZmTlr4sSJ23B4jaW7ZIkzdJIkjTz1DHT3AFMjorVYwHAmMK9Xn+uozM4REROonIJdBvweOC4iRkfEGCoLIpYW/f4N2AP4x+oNRcS+VS/f1t1fFd0lS7yGTpKkkaduyx0zc0NEnA/cDIwCrsjMxRFxMbAgM+cV770lIpYAG4EPZ2Y5Iq4BTgAWUlkgMT8zr4+IScC/AA8D90UEwJcz82vA30fE24ANwArgffU6tkbUU1TYU66SJI04da1fkZk3Ajf2aruw6nkCFxSP6j4bgXP72N5yIPrZ18eolEBRH9o6Otlrd0uWSJI0Eg31oghtJ+3lTu8QIUnSCGWgaxJtHV3ew1WSpBHKQNcEVq3dQMeqtc7QSZI0QhnomkD3PVxbXOEqSdKIZKBrAj0rXA10kiSNSAa6JvBiDTqvoZMkaSQy0DWBUlGyZNedLFkiSdJIZKBrAqVyp6dbJUkawQx0TaBU7vIOEZIkjWAGuhFu1doNPPuntd7DVZKkEcxAN8K1FwsiWq1BJ0nSiGWgG+FKHZWSJa5wlSRp5DLQjXDdJUtcFCFJ0shloBvhSh2dTLRkiSRJI5qBboRrL3fR6uycJEkjmoFuhGsrd3r9nCRJI5yBbgTrLEqWtLjCVZKkEc1AN4K5IEKSpOZgoBvB2suVkiXeJUKSpJHNQDeCtXVUZui8S4QkSSObgW4Eay9XSpbsZskSSZJGNAPdCFbq6KLFFa6SJI14BroRrFTudEGEJElNwEA3QnWu3cAzliyRJKkpGOhGqJ4Vrs7QSZI04m0x0EXEjyLiLyPC8NdAumvQeZcISZJGvlpC2mXAfwMei4hPR8Rr6jwmDYKeosKecpUkacTbYqDLzJ9n5tnAa4ES8POIuDMi/iYixtR7gNo6pY5OJuxmyRJJkppBTadRI2I88D7g/cD9wBepBLyf1W1k2ialchet3iFCkqSmsMXpm4j4MfAa4NvAWzPzD8VbV0fEgnoOTluv1NHJsQdOHOphSJKk7aCW83Ffysxb+3ojM2cN8ng0CLrWVUqWtHr9nCRJTaGWU67TI2Jc94uI2DMi/q6OY9I2KnVUSpa4wlWSpOZQS6D7QGY+1/0iM1cCH6jfkLSt2rtXuFqDTpKkplBLoBsVEdH9IiJGATvWb0jaVm2WLJEkqanUcg3dfCoLIP5v8frcok3DVHtHlyVLJElqIrX8i/8RKiHug8XrnwFfq9uItM3ayp20eP2cJElNY4uBLjM3AV8pHmoA7eVO3jDVkiWSJDWLWurQTQU+BUwHxna3Z+YBdRyXtlLXug388YW1ztBJktREalkU8Q0qs3MbgDcC3wK+U89Baeu1lyslS1wQIUlS86gl0O2cmbcAkZntmflJ4C/rOyxtrVKHJUskSWo2tSyKWBsROwCPRcT5wJPAbvUdlrZWqWxRYUmSmk0tM3T/AOwC/D1wBPAu4L21bDwiToqIRyLi8Yj4aD99zoiIJRGxOCK+W9X+2aJtaUR8qbsWXkQcERELi21Wt78yIn4WEY8Vf+5ZyxhHmlJHJxN225Hdx44Z6qFIkqTt5GUDXVFE+K8zc1VmLs/Mv8nM0zLzri1tuPjspcDJVBZUnBUR03v1mQp8DDg6Mw8G/rFonwMcDRwKHAK8Djiu+NhXqNypYmrxOKlo/yhwS2ZOBW4pXjedUrnT062SJDWZlz3lmpkbI+KYrdz2kcDjmbkMICK+D7wdWFLV5wPApcXtxMjMZ7p3TWVF7Y5AAGOAP0bEvsArugNlRHwLeAdwU7Ht44vPfxP4JZUaekPrpo/C0wu32+7+x9Mr2WPnMfANz4pLkrTd7DMDTv70kO2+lmvo7o+IecAPgc7uxsz80RY+tx/wRNXr5cDre/U5ECAifg2MAj6ZmfMz8zcRcSvwByqB7suZuTQiZhXbqd7mfsXzvTPzD8Xzp4G9+xpURJwDnAMwefLkLRxCY9mYyfqNm9h5TC1n0iVJ0khRS6AbC5SBE6raEthSoKt1/1OpzKxNAm6LiBnABGBa0Qbws4h4A7C6lo1mZkZE9vPe5cDlALNmzeqzz6Dajmn90T+8wJlfvJ3/OOFw9jvsVdttv5IkaWjVcqeIv9nKbT8J7F/1elLRVm058NvMXA+0RcSjvBjw7srMVQARcRNwFPBtXgx5vbf5x4jYNzP/UJyafYYm016uTKC2WoNOkqSmssVzcxHxjYi4ovejhm3fA0yNiNaI2BE4E5jXq891FNe9RcQEKqdglwG/B46LiNERMYbKgoilxSnVFyJidrG69T3AfxXbmseLq2/fW9XeNNo6LFkiSVIzquWU6w1Vz8cCpwJPbelDmbmhqFt3M5Xr467IzMURcTGwIDPnFe+9JSKWABuBD2dmOSKuoXKKdyGV07vzM/P6YtN/B1wJ7ExlMcRNRfungR9ExN8C7cAZNRzbiNJetmSJJEnNKDIHdhlZUWT4jsycU58hbT+zZs3KBQsWDPUwBs1f/9/fsGFTcu0HG/6nkSRJvUTEvZk5q6/3tmY55FRgr20bkuqhvdxlDTpJkprQFk+5RsSfqJz27PY0w6G+mzazet1Gnn5hDS1ePydJUtOpZZXr7ttjINo27SsqK1xbXOEqSVLTqWWV66kRsUfV63ER8Y76DksDVeooAp2nXCVJajq1XEP3icx8vvtFZj4HfKJ+Q9LWKJWLkiUTPOUqSVKzqSXQ9dWnlnIn2o5KHZ2M33VHXmHJEkmSmk4tgW5BRHw+Iv6seHweuLfeA9PAlMqdXj8nSVKTqiXQfQhYB1wNfB9YA5xXz0Fp4EodXd4hQpKkJlXLKtdO4KPbYSzaSt0lS1pdECFJUlOqZZXrzyJiXNXrPSPi5voOSwPRXbJkiqdcJUlqSrWccp1QrGwFIDNX4p0ihpVSR2WFqzN0kiQ1p1oC3aaImNz9IiKmsPmdIzTESuXuGTqvoZMkqRnVUn7kX4A7IuJXQABvAM6p66g0IO1lS5ZIktTMalkUMT8iXgvMLpr+MTM76jssDURbR6crXCVJamK1nHIF2Ag8A7wATI+IY+s3JA1Ue7nLGnSSJDWxLc7QRcT7gX8AJgEPUJmp+w1wQn2HplqsXreRPzy/xnu4SpLUxGqZofsH4HVAe2a+ETgceO7lP6Lt5fcrKitcnaGTJKl51RLo1mTmGoCI2CkzHwZeU99hqVZtHZUVri1eQydJUtOqZZXr8qKw8HXAzyJiJdBe32GpVu3dJUs85SpJUtOqZZXrqcXTT0bErcAewPy6jko1K5U7eeWuO7LHzpYskSSpWdUyQ9cjM39Vr4Fo65Q6ujzdKklSk6u1bImGqVK50xWukiQ1OQNdA1uzvihZ4gpXSZKamoGugbWXKyVLvEuEJEnNzUDXwErFCtdWZ+gkSWpqBroGVuqwZIkkSTLQNbRSucuSJZIkyUDXyEodnV4/J0mSDHSNrL3cSaunWyVJanoGuga1Zv1Gnnp+jdfPSZIkA12j+v2KSsmSlgmecpUkqdkZ6BpUW7HC1btESJIkA12Dai8b6CRJUoWBrkG1dXSx5y5j2GMXS5ZIktTsDHQNqr3c6T1cJUkSYKBrWKWOTk+3SpIkwEDXkLpLlhjoJEkSGOgakiVLJElSNQNdAypZskSSJFUx0DWgkiVLJElSlboGuog4KSIeiYjHI+Kj/fQ5IyKWRMTiiPhu0fbGiHig6rEmIt5RvHd7VftTEXFd0X58RDxf9d6F9Ty2oVQqW7JEkiS9aHS9NhwRo4BLgROB5cA9ETEvM5dU9ZkKfAw4OjNXRsReAJl5KzCz6PNK4HHgp8V7b6j6/LXAf1Xt9vbMPKVexzRclDo6vYerJEnqUc8ZuiOBxzNzWWauA74PvL1Xnw8Al2bmSoDMfKaP7ZwO3JSZXdWNEfEK4ATgukEf+TDXXu6i1Rp0kiSpUM9Atx/wRNXr5UVbtQOBAyPi1xFxV0Sc1Md2zgS+10f7O4BbMvOFqrajIuLBiLgpIg7elsEPV5WSJauZMt4VrpIkqaJup1wHsP+pwPHAJOC2iJiRmc8BRMS+wAzg5j4+exbwtarX9wFTMnNVRPwFlZm7qb0/FBHnAOcATJ48efCOZDt5YkUXmThDJ0mSetRzhu5JYP+q15OKtmrLgXmZuT4z24BH2TyEnQH8ODPXV38oIiZQOaX7k+62zHwhM1cVz28ExhT9NpOZl2fmrMycNXHixK0/uiHSVpQs8Ro6SZLUrZ6B7h5gakS0RsSOVE6dzuvV5zoqs3PdIe1AYFnV+2fR9+nW04EbMnNNd0NE7BMRUTw/ksqxlQfnUIaP9nLlUsJWA50kSSrU7ZRrZm6IiPOpnC4dBVyRmYsj4mJgQWbOK957S0QsATYCH87MMkBEtFCZ4ftVH5s/E/h0r7bTgQ9GxAZgNXBmZubgH9nQait3Ms6SJZIkqUqMwMxTs1mzZuWCBQuGehgDcvbX7qJz7UauO+/ooR6KJEnajiLi3syc1dd73imiwZQ6umhxhaskSapioGsg3SVLWlzhKkmSqhjoGkh3yRLv4SpJkqoZ6BpIqVjh6gydJEmqZqBrIKWiBp3X0EmSpGoGugZSKkqWjNtlx6EeiiRJGkYMdA2kVO70DhGSJOklDHQNpNTRRaunWyVJUi8GugbRXbLEGTpJktSbga5BLF9ZKVnS6gpXSZLUi4GuQZQ6KiVLpnjKVZIk9WKgaxClcqVkiTN0kiSpNwNdgyiVO9ljZ0uWSJKklzLQNYhSR5d3iJAkSX0y0DWIUrnTO0RIkqQ+GegawNoNG3nqudW0WLJEkiT1wUDXAJ5YsZpNCS0TnKGTJEkvZaBrAKWOygpXZ+gkSVJfDHQNoLtkiYFOkiT1xUDXALpLluy5qyVLJEnSSxnoGkB7ucsVrpIkqV8GugbQ1tFpDTpJktQvA90w112yZIrXz0mSpH4Y6Ia57pIlrZYskSRJ/TDQDXPtxQpXZ+gkSVJ/DHTDXFtRg67VQCdJkvphoBvm2stdvGLsaMbtMmaohyJJkoYpA90wVyp30jphVyJiqIciSZKGKQPdMFcqd3r9nCRJelkGumFs3YZNPLlytUWFJUnSyzLQDWNPrOxiU2JRYUmS9LIMdMNYqcOSJZIkacsMdMNYqdwFQKszdJIk6WUY6IaxUkcnu48dzZ6WLJEkSS/DQDeMWbJEkiTVwkA3jFmyRJIk1cJAN0x1lyxptWSJJEnaAgPdMNVdssQZOkmStCUGumGqvVwpWWINOkmStCUGumGqraNSssS7REiSpC2pa6CLiJMi4pGIeDwiPtpPnzMiYklELI6I7xZtb4yIB6oeayLiHcV7V0ZEW9V7M4v2iIgvFft6KCJeW89jq7f2cqVkySt33XGohyJJkoa50fXacESMAi4FTgSWA/dExLzMXFLVZyrwMeDozFwZEXsBZOatQHdQeyXwOPDTqs1/ODOv6bXLk4GpxeP1wFeKPxtSW0cnLeMtWSJJkrasnjN0RwKPZ+ayzFwHfB94e68+HwAuzcyVAJn5TB/bOR24KTO7trC/twPfyoq7gHERse+2HcLQaS93ef2cJEmqST0D3X7AE1Wvlxdt1Q4EDoyIX0fEXRFxUh/bORP4Xq+2S4rTql+IiJ0GsL+GsG7DJpav7PL6OUmSVJOhXhQxmsop0uOBs4CvRsS47jeLGbYZwM1Vn/kYcBDwOuCVwEcGssOIOCciFkTEgmeffXbbRl8ny4uSJS2WLJEkSTWoZ6B7Eti/6vWkoq3acmBeZq7PzDbgUSoBr9sZwI8zc313Q2b+oTituhb4BpVTu7Xuj8y8PDNnZeasiRMnbuWh1Vepp2SJM3SSJGnL6hno7gGmRkRrROxI5dTpvF59rqMyO0dETKByCnZZ1ftn0et0a/d1cVFZLfAOYFHx1jzgPcVq19nA85n5h0E9ou2k1FOyxBk6SZK0ZXVb5ZqZGyLifCqnS0cBV2Tm4oi4GFiQmfOK994SEUuAjVRWr5YBIqKFyozbr3pt+qqImAgE8ADw/xftNwJ/QWVFbBfwN/U6tnorlTvZfSdLlkiSpNrULdABZOaNVIJWdduFVc8TuKB49P5siT4WNWTmCf3sK4Hztm3Ew0OpWOFqyRJJklSLoV4UoT6UOjqZ4gpXSZJUIwPdMNNdsqTVGnSSJKlGBrphprtkyRQXREiSpBoZ6IaZ9nJlhWurJUskSVKNDHTDTFtHpQadM3SSJKlWBrphpr0oWTLekiWSJKlGBrphpq3cxZQJu1iyRJIk1cxAN8y0lzu9Q4QkSRoQA90wsn7jJpavXG2gkyRJA2KgG0aWr1zNxk1JizXoJEnSABjohpFSscK1xbtESJKkATDQDSOlchHonKGTJEkDYKAbRkodnexmyRJJkjRABrphpFTuosWSJZIkaYAMdMNIqdzpHSIkSdKAGeiGie6SJa0GOkmSNEAGumGiu2TJFFe4SpKkATLQDRPdK1xbXeEqSZIGyEA3THTXoPMaOkmSNFAGumGivdzFbjuNZsJuliyRJEkDY6AbJto6Opky3pIlkiRp4Ax0w0R7udM7REiSpK1ioBsG1m/cxBMrV3sPV0mStFUMdMPAk0XJkhYXREiSpK1goBsG2oqSJZ5ylSRJW8NANwy0FyVLnKGTJElbw0A3DJTKXey64yhLlkiSpK1ioBsGSsUKV0uWSJKkrWGgGwZKHZ2ebpUkSVvNQDfE1m/cxPKVq2mZYMkSSZK0dQx0Q+zJlavZsCm9h6skSdpqBrohVipKlrRaskSSJG0lA90QKxUlS6Z4lwhJkrSVDHRDrLtkycTddhrqoUiSpAZloBtipXInU8ZbskSSJG09A90Qay93ef2cJEnaJga6IbRh4yaeWNHl9XOSJGmbGOiG0JPPVUqWtDhDJ0mStoGBbgi1FStcvUuEJEnaFga6IdRe7gLwLhGSJGmbGOiGUFtHpyVLJEnSNqtroIuIkyLikYh4PCI+2k+fMyJiSUQsjojvFm1vjIgHqh5rIuIdxXtXFdtcFBFXRMSYov34iHi+6jMX1vPYBkO7JUskSdIgGF2vDUfEKOBS4ERgOXBPRMzLzCVVfaYCHwOOzsyVEbEXQGbeCsws+rwSeBz4afGxq4B3Fc+/C7wf+Erx+vbMPKVexzTYSuUupu27+1APQ5IkNbh6ztAdCTyemcsycx3wfeDtvfp8ALg0M1cCZOYzfWzndOCmzOwq+tyYBeBuYFLdjqCOukuWuCBCkiRtq3oGuv2AJ6peLy/aqh0IHBgRv46IuyLipD62cybwvd6NxanWdwPzq5qPiogHI+KmiDh424ZfXz0lSwx0kiRpG9XtlOsA9j8VOJ7KTNttETEjM58DiIh9gRnAzX189jLgtsy8vXh9HzAlM1dFxF8A1xXb3kxEnAOcAzB58uTBPZoBKPWscDXQSZKkbVPPGbongf2rXk8q2qotB+Zl5vrMbAMeZfMQdgbw48xcX/2hiPgEMBG4oLstM1/IzFXF8xuBMRExofegMvPyzJyVmbMmTpy49Ue3jUo9NegsWSJJkrZNPQPdPcDUiGiNiB2pnDqd16vPdVRm5yjC14HAsqr3z6LX6daIeD/w58BZmbmpqn2fKJaLRsSRVI6tPJgHNJhK5U522XEUE3e3ZIkkSdo2dTvlmpkbIuJ8KqdLRwFXZObiiLgYWJCZ84r33hIRS4CNwIczswwQES1UZvh+1WvT/wm0A78p8tuPMvNiKosnPhgRG4DVwJnFwolhqdRhyRJJkjQ46noNXXHq88ZebRdWPU8qp00v6PVRMrPESxdRkJl9jjkzvwx8edtGvP20l7s4yJIlkiRpEHiniCGwYeMmfr+iiymucJUkSYPAQDcEnnpuDRs2Ja0GOkmSNAgMdEOgrVxZ4TrFFa6SJGkQGOiGQHsR6FqtQSdJkgaBgW4ItHVYskSSJA0eA90QaC93WbJEkiQNGgPdECh1dHqHCEmSNGgMdNvZho2beGJll/dwlSRJg8ZAt5099dwa1m9MZ+gkSdKgMdBtZ6VihWuLNegkSdIgMdBtZz2BzlOukiRpkBjotrNSRxc7jxnFXpYskSRJg8RAt52Vyp1MGb+LJUskSdKgMdBtZ6Vyp3eIkCRJg8pAtx1t2LiJJ1ZUigpLkiQNFgPddvSH5yslS1onWLJEkiQNHgPddtTWUVnh6gydJEkaTAa67ai9KFniNXSSJGkwGei2ozZLlkiSpDow0G1H7ZYskSRJdWCg247ayp3e8kuSJA06A912snFT8sSKLm/5JUmSBp2Bbjt56rnVrN+YtIy3ZIkkSRpcBrrtpFSscHWGTpIkDTYD3XZSKmrQeQ2dJEkabAa67aRU7mLsmB3Y+xWWLJEkSYPLQLedlDoqK1wtWSJJkgabgW47KVmyRJIk1YmBbjuolCxZzZQJrnCVJEmDz0C3HTz13GrWbdxEqzN0kiSpDgx020F3yZIpBjr9v/buNsaOqo7j+PdHKyC0AcFCtC20SlGLSNENUatGqS8gGkGDKCohxMgbUB6MjzHRGF9oYkRfEB8iGgwImApKjApRSI0mIgWq2BZNUwoUMUBTKrTBQvn74p7q0qzaXTs7zvb7STa5c+bsmf/NSe/+OjP3jCRJHTDQTYNNW3YAsNg16CRJUgcMdNNg02PbOfh5B3DUXJcskSRJ+56Bbhrc377hesABLlkiSZL2PQPdNLjvse0c6zNcJUlSRwx0Hdu9ZInPcJUkSV0x0HVs95IlLiosSZK6YqDr2P3tG64GOkmS1BUDXcfua2vQLfIpEZIkqSMGuo7d35YsOXruwX2XIkmSZqhOA12S05L8KcmGJJ/8N33OTrIuydok329tb0myZtzPU0nObPsWJ7m9jXl9kgNb+0Fte0Pbv6jL97a3Nm3ZzrFHuGSJJEnqTmeBLsks4ArgdGApcE6SpXv0WQJ8ClheVScAlwBU1W1VtayqlgGnAjuAW9qvfQm4vKqOA7YCH2ztHwS2tvbLW7/ebdqyw8utkiSpU12eoTsF2FBVG6tqJ3AdcMYefT4EXFFVWwGq6pEJxjkL+FlV7UgSRgFvZdt3FXBme31G26btX9H692bXs8UDW3b4hQhJktSpLgPdfODBcdubW9t4xwPHJ/lNkt8mOW2Ccd4LXNteHwk8XlXPTDDmP4/X9m9r/Xvz8La2ZIlr0EmSpA7N/j84/hLgzcAC4FdJTqyq5vQIlwAABnBJREFUxwGSvAg4Ebh5Xx0wyQXABQDHHHPMvhp2Qjt27mLZwsNZctScTo8jSZL2b12eoXsIWDhue0FrG28zcFNVPV1V9wF/ZhTwdjsbuLGqnm7bW4DDk+wOouPH/Ofx2v7DWv/nqKpvVdVYVY3Nmzdvym9ubxx/9Fx+dOFyxhYd0elxJEnS/q3LQHcHsKR9K/VARpdOb9qjz48YnZ0jyQsZXYLdOG7/OfzrcitVVcBtjO6rAzgP+HF7fVPbpu2/tfWXJEma0ToLdO0+tosYXS5dD/ygqtYm+XySd7RuNwNbkqxjFNQ+VlVbANqyIwuBVXsM/QngsiQbGN0jd2VrvxI4srVfBky4TIokSdJMk/35JNbY2FitXr267zIkSZL+qyR3VtXYRPt8UoQkSdLAGegkSZIGzkAnSZI0cAY6SZKkgTPQSZIkDZyBTpIkaeAMdJIkSQNnoJMkSRo4A50kSdLAGegkSZIGzkAnSZI0cAY6SZKkgTPQSZIkDZyBTpIkaeAMdJIkSQOXquq7ht4keRS4fxoO9ULgsWk4jrrh/A2fczh8zuGwOX/7xrFVNW+iHft1oJsuSVZX1VjfdWhqnL/hcw6HzzkcNueve15ylSRJGjgDnSRJ0sAZ6KbHt/ouQP8T52/4nMPhcw6HzfnrmPfQSZIkDZxn6CRJkgbOQNehJKcl+VOSDUk+2Xc9mpwkC5PclmRdkrVJLu67Jk1ekllJ7k7yk75r0eQlOTzJyiT3Jlmf5HV916TJSXJp+wz9Y5Jrkxzcd00zkYGuI0lmAVcApwNLgXOSLO23Kk3SM8BHq2op8FrgQudwkC4G1vddhKbsa8DPq+rlwEk4l4OSZD7wEWCsql4JzALe229VM5OBrjunABuqamNV7QSuA87ouSZNQlU9XFV3tddPMPpDMr/fqjQZSRYAbwO+3XctmrwkhwFvAq4EqKqdVfV4v1VpCmYDz08yGzgE+EvP9cxIBrruzAceHLe9GcPAYCVZBJwM3N5vJZqkrwIfB57tuxBNyWLgUeC77bL5t5Mc2ndR2ntV9RDwZeAB4GFgW1Xd0m9VM5OBTvovkswBfghcUlV/67se7Z0kbwceqao7+65FUzYbeDXw9ao6GdgOeD/ygCR5AaOrU4uBFwOHJvlAv1XNTAa67jwELBy3vaC1aUCSPI9RmLumqm7oux5NynLgHUk2Mbrl4dQkV/dbkiZpM7C5qnafGV/JKOBpON4K3FdVj1bV08ANwOt7rmlGMtB15w5gSZLFSQ5kdBPoTT3XpElIEkb37qyvqq/0XY8mp6o+VVULqmoRo39/t1aVZwYGpKr+CjyY5GWtaQWwrseSNHkPAK9Nckj7TF2BX2zpxOy+C5ipquqZJBcBNzP6Vs93qmptz2VpcpYD5wL3JFnT2j5dVT/tsSZpf/Nh4Jr2H+ONwPk916NJqKrbk6wE7mK0csDd+NSITvikCEmSpIHzkqskSdLAGegkSZIGzkAnSZI0cAY6SZKkgTPQSZIkDZyBTpKmSZI3J/lJ33VImnkMdJIkSQNnoJOkPST5QJLfJVmT5JtJZiV5MsnlSdYm+WWSea3vsiS/TfKHJDe2Z1eS5Lgkv0jy+yR3JXlpG35OkpVJ7k1yTVs9nyRfTLKujfPlnt66pIEy0EnSOEleAbwHWF5Vy4BdwPuBQ4HVVXUCsAr4bPuV7wGfqKpXAfeMa78GuKKqTmL07MqHW/vJwCXAUuAlwPIkRwLvBE5o43yh23cpaaYx0EnSc60AXgPc0R75toJR8HoWuL71uRp4Q5LDgMOralVrvwp4U5K5wPyquhGgqp6qqh2tz++qanNVPQusARYB24CngCuTvAvY3VeS9oqBTpKeK8BVVbWs/bysqj43Qb+pPjfx7+Ne7wJmV9UzwCnASuDtwM+nOLak/ZSBTpKe65fAWUmOAkhyRJJjGX1entX6vA/4dVVtA7YmeWNrPxdYVVVPAJuTnNnGOCjJIf/ugEnmAIdV1U+BS4GTunhjkmau2X0XIEn/T6pqXZLPALckOQB4GrgQ2A6c0vY9wug+O4DzgG+0wLYROL+1nwt8M8nn2xjv/g+HnQv8OMnBjM4QXraP35akGS5VU71qIEn7jyRPVtWcvuuQpIl4yVWSJGngPEMnSZI0cJ6hkyRJGjgDnSRJ0sAZ6CRJkgbOQCdJkjRwBjpJkqSBM9BJkiQN3D8AUk43BI59z2cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "dk9H1Sxn3vjx",
        "outputId": "92dc4f5f-4083-4aee-aaf3-3ae896b8ffaf"
      },
      "source": [
        "xpoints = np.arange(len(trainLossList))\n",
        "ypoints0 = trainLossList\n",
        "ypoints2 = valLossList\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10,8]\n",
        "plt.plot(xpoints, ypoints0 , label = \"$ Training Loss $\" )\n",
        "plt.plot(xpoints, ypoints2, label = \"$ Validation Loss $\" )\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.title(\"model performance\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss \")\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ9kTRpeWwoy"
      },
      "source": [
        "### A utility function to classify any tweets\n",
        "\n",
        "1.   saved weights are used to classify any input string to predict a label\n",
        "2.   a cached tokenizer which was saved earlier is used\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    \n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    #print(tokenized)\n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized] \n",
        "    #print(indexed)       \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    #print(tensor)\n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    #print(tensor)\n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    #print(length_tensor)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    #print(pred.size(),pred)\n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgwS0wUCdtOi"
      },
      "source": [
        "### Classify a single sentence and print the hidden state at each step of encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "129bb441-718d-4b07-f20e-bbe7594af5a3"
      },
      "source": [
        "printEncoderDecoderOutput = True\n",
        "classify_tweet(\"An invalid explanation for why Nixon will let women on the army.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encdr word  0 torch.Size([1, 100]) tensor([[-1.8710e-03, -8.0427e-01, -6.1747e-11, -3.7839e-02, -8.4277e-03,\n",
            "         -1.7091e-02, -2.6354e-05, -2.4499e-04,  7.9232e-01, -6.6541e-03,\n",
            "          8.2659e-11, -6.4073e-06, -9.3472e-02,  7.1891e-01, -7.6157e-01,\n",
            "         -7.0244e-01, -2.9770e-07,  7.9476e-01, -8.6679e-01,  8.4065e-07,\n",
            "          6.9593e-01,  7.6414e-01,  7.6146e-01,  1.5395e-03,  8.8270e-02,\n",
            "         -6.6078e-07,  7.1764e-02, -7.4168e-01,  6.1294e-01, -6.5134e-01,\n",
            "         -7.6126e-01,  6.9115e-03, -6.2946e-02,  5.2571e-01, -7.1021e-01,\n",
            "         -6.6858e-02,  6.7826e-01,  2.6072e-03, -7.2935e-01, -5.3951e-05,\n",
            "          7.3473e-08,  7.6043e-01, -7.0153e-01,  7.7333e-01, -6.5393e-01,\n",
            "          8.9022e-04, -5.3442e-07, -6.2792e-02, -1.0654e-10,  7.4090e-01,\n",
            "         -2.7676e-05,  6.9301e-01, -2.8549e-01, -7.3232e-01,  1.3171e-07,\n",
            "         -6.9449e-01,  7.5401e-01, -3.7342e-11, -7.3943e-01, -1.9820e-02,\n",
            "          1.0424e-03,  1.1207e-04, -4.6235e-22, -1.0200e-08,  7.9701e-01,\n",
            "         -2.7369e-09, -1.8870e-01,  4.4296e-01, -8.5802e-01,  4.1583e-14,\n",
            "          3.8245e-02,  7.7617e-01, -1.1807e-03, -7.1285e-01, -5.8152e-01,\n",
            "         -3.4256e-02,  2.7184e-02,  2.6511e-10, -7.5964e-01,  1.2416e-04,\n",
            "          6.4464e-01, -7.0735e-01, -7.0257e-03, -3.0702e-02, -9.9958e-14,\n",
            "         -8.0186e-06, -1.2767e-04, -7.7026e-01,  7.2611e-01, -4.8855e-03,\n",
            "         -4.9267e-07,  5.1638e-04,  2.7243e-18,  1.7389e-10, -3.3735e-06,\n",
            "          1.9561e-01,  1.9770e-05, -7.5814e-01, -5.8209e-04,  7.6071e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  1 torch.Size([1, 100]) tensor([[ 4.4919e-01, -1.3640e-03, -3.8265e-14, -6.5007e-01, -7.9563e-01,\n",
            "         -4.4452e-09,  9.9040e-02, -7.7525e-03,  7.2631e-02,  1.8974e-01,\n",
            "          4.7622e-16, -2.4541e-02,  2.9577e-20,  1.2247e-03, -2.7754e-03,\n",
            "         -1.8687e-05,  5.4580e-04, -2.9173e-06, -1.7394e-01, -6.7809e-01,\n",
            "          2.1590e-09, -5.0160e-02,  9.2056e-03,  7.5190e-01, -2.3817e-08,\n",
            "         -2.9716e-03, -1.1448e-01, -2.7762e-01,  7.8472e-02, -1.4441e-02,\n",
            "         -2.0839e-01,  7.4063e-01, -9.5916e-01,  1.1816e-04, -9.0861e-06,\n",
            "         -7.3502e-09,  1.5688e-04,  3.0521e-02,  4.0552e-02,  2.3867e-03,\n",
            "         -1.9014e-01,  5.6316e-02,  1.0260e-04,  1.7385e-08, -7.1152e-04,\n",
            "          5.7004e-08, -2.4205e-01, -4.6986e-05,  2.6555e-01,  7.5456e-01,\n",
            "         -3.5942e-12, -1.1207e-01,  3.9830e-01, -3.1992e-02,  5.0033e-03,\n",
            "          6.9750e-06,  1.6633e-04, -1.2140e-02, -8.0994e-08, -7.3306e-01,\n",
            "         -1.3585e-02, -1.3840e-08, -1.5726e-11, -1.6366e-05,  1.1722e-07,\n",
            "         -4.0132e-11,  2.4935e-02,  4.7871e-01,  7.6105e-01,  3.1331e-04,\n",
            "          8.4180e-01,  8.6210e-05,  6.4950e-04, -1.7245e-01, -1.6178e-01,\n",
            "         -3.5726e-03, -5.0847e-01, -4.9250e-01, -1.2365e-03, -1.3442e-07,\n",
            "          1.1578e-03, -2.2452e-09,  5.4949e-01, -3.2034e-07, -7.6159e-01,\n",
            "         -7.3239e-05, -2.2099e-17, -1.0716e-04,  2.4072e-07, -4.6313e-10,\n",
            "          3.1549e-14, -1.9295e-03,  1.2351e-14,  3.1879e-01, -1.0875e-03,\n",
            "          3.1058e-03,  2.5394e-03, -2.7875e-01, -3.5399e-11, -7.9416e-02]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  2 torch.Size([1, 100]) tensor([[ 7.3750e-01, -7.9441e-01, -1.8194e-06,  2.1156e-01, -1.5686e-01,\n",
            "          3.9432e-01,  4.5617e-06, -8.4207e-01,  4.0767e-07,  2.4453e-12,\n",
            "          1.4174e-12, -3.9222e-09, -7.6152e-01, -3.1800e-02, -4.5048e-02,\n",
            "         -9.7313e-02,  1.3900e-03,  4.1683e-01, -4.1216e-01, -1.2998e-10,\n",
            "         -6.8561e-12,  7.5631e-01,  5.1152e-06,  1.3346e-08, -7.6159e-01,\n",
            "         -9.0789e-08,  5.9417e-01, -2.3471e-01,  5.5605e-01, -9.1215e-03,\n",
            "         -3.4759e-03,  2.3810e-11, -9.5820e-15, -4.6662e-01,  3.2495e-01,\n",
            "         -2.7262e-06, -4.7297e-13, -6.8804e-01,  1.7135e-06,  1.8321e-10,\n",
            "         -2.0266e-01, -7.1664e-01, -1.1788e-02,  8.7965e-01, -3.1399e-11,\n",
            "         -9.5058e-12, -1.8245e-03, -4.6086e-01,  5.9536e-12,  9.7495e-01,\n",
            "         -3.0439e-04, -1.1221e-01, -1.8989e-04, -4.4031e-05,  1.8603e-05,\n",
            "         -7.4621e-04, -4.8925e-03, -2.9671e-04, -9.6023e-01, -8.5472e-01,\n",
            "         -5.3781e-01, -8.4721e-03, -1.3943e-14,  7.5913e-01, -5.1087e-13,\n",
            "          1.5875e-01, -5.9026e-01,  6.6487e-12,  1.6062e-02,  1.6610e-03,\n",
            "          7.8022e-01,  5.7327e-04,  4.7067e-02,  5.8404e-06, -3.4405e-07,\n",
            "         -1.2937e-08, -3.6771e-01, -2.1246e-07,  1.2093e-04,  7.5392e-01,\n",
            "          5.4536e-02, -5.4018e-02,  9.2431e-01, -3.8162e-03,  2.8819e-02,\n",
            "          2.6540e-01, -6.6465e-09, -6.1361e-01,  9.9032e-01, -2.4998e-06,\n",
            "         -7.3873e-08, -4.7378e-03,  3.7981e-11,  1.0273e-08,  7.5985e-01,\n",
            "         -7.3371e-01,  7.4275e-01, -3.6588e-02,  7.0699e-01,  8.6286e-02]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  3 torch.Size([1, 100]) tensor([[ 6.7957e-01,  1.3282e-02,  2.6443e-01, -2.2496e-03, -1.9697e-02,\n",
            "         -6.9500e-03,  6.1831e-01, -4.0332e-18, -7.6150e-01,  1.1014e-05,\n",
            "         -3.1232e-01, -1.4010e-02, -3.1855e-02, -5.8333e-01, -6.9389e-04,\n",
            "          7.6093e-01, -1.4293e-15, -4.4500e-01,  2.9193e-12,  7.5732e-01,\n",
            "          7.6158e-01, -7.2006e-04, -1.3679e-02,  1.5109e-01,  2.1149e-04,\n",
            "          7.6145e-01,  9.9658e-24, -5.5781e-01, -6.6678e-01, -7.5870e-01,\n",
            "         -9.2087e-01,  6.3124e-07, -6.6880e-01, -5.3424e-06,  5.6333e-16,\n",
            "         -4.5410e-03, -6.7126e-01, -5.4482e-17,  8.6506e-01, -7.6136e-01,\n",
            "         -5.9897e-32,  1.4264e-18,  7.5769e-01, -4.5648e-07,  7.6159e-01,\n",
            "          7.6123e-01,  6.1327e-01, -2.3076e-01,  7.6139e-01, -2.5450e-04,\n",
            "          7.6150e-01, -2.5656e-02,  7.5869e-01,  6.7820e-10,  7.6163e-01,\n",
            "         -9.5713e-01, -5.1999e-05, -1.1597e-08, -9.9449e-01, -8.4959e-01,\n",
            "         -3.3957e-08, -8.7787e-01, -7.6159e-01, -7.5912e-01,  2.7493e-01,\n",
            "          1.9843e-10,  1.5020e-01, -6.7671e-04, -1.6809e-11, -4.2961e-05,\n",
            "         -6.7947e-01, -2.5123e-07,  9.7678e-06,  2.2129e-06,  4.3324e-07,\n",
            "          7.2819e-01, -1.8472e-33, -2.8258e-21, -7.3335e-01,  2.7260e-26,\n",
            "         -7.6091e-01, -8.2732e-01, -2.9146e-14, -2.7030e-07,  1.5516e-07,\n",
            "         -2.9181e-05, -1.5851e-19,  2.6194e-01,  1.4129e-05,  6.4406e-01,\n",
            "          7.6022e-01, -7.6847e-01, -6.9955e-07, -7.6127e-01,  3.5327e-05,\n",
            "         -9.6402e-01,  1.0746e-05, -7.7134e-01, -5.1309e-05,  5.2947e-14]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  4 torch.Size([1, 100]) tensor([[ 6.6287e-11,  9.5362e-05, -1.5209e-05, -9.5474e-19,  9.2174e-04,\n",
            "         -5.8929e-01, -7.6111e-01,  3.0600e-29,  2.1189e-04,  7.5573e-01,\n",
            "         -3.1230e-01, -6.8934e-05, -7.0263e-01, -7.6162e-01, -3.8863e-09,\n",
            "          7.0212e-01, -6.6286e-10,  5.0818e-01, -1.0095e-16,  7.5732e-01,\n",
            "          1.2566e-06,  8.2254e-11,  7.6159e-01,  7.7342e-01,  5.0416e-29,\n",
            "          2.5234e-01,  9.0951e-28, -3.8199e-14,  1.9252e-01, -1.5037e-08,\n",
            "         -1.1904e-01, -1.7865e-02, -9.4769e-01,  2.2392e-17, -8.8497e-21,\n",
            "          7.5968e-01,  2.9163e-04, -2.0700e-19,  3.0324e-01,  3.2842e-05,\n",
            "         -7.6159e-01,  1.7740e-04, -9.2386e-03, -3.5783e-02, -1.9312e-05,\n",
            "         -3.3559e-03,  9.3270e-01, -7.6161e-01,  9.6399e-01,  7.5971e-01,\n",
            "          4.6622e-02, -3.0035e-12, -6.8786e-03, -1.7006e-04, -2.6000e-01,\n",
            "         -7.5105e-01,  3.3078e-04, -4.1149e-03, -1.9194e-02, -5.0365e-09,\n",
            "          5.5846e-09, -7.7192e-01, -3.1461e-02, -4.1584e-20,  5.2222e-02,\n",
            "         -4.2058e-07,  5.0141e-07, -1.7266e-04,  6.3796e-01, -6.2466e-01,\n",
            "         -1.9403e-16,  7.5916e-01, -1.2187e-02, -7.6155e-01,  7.4815e-01,\n",
            "          7.2473e-01, -3.9613e-05, -7.6159e-01,  7.6159e-01,  3.9456e-20,\n",
            "          6.4677e-01, -1.3675e-01, -1.0321e-26, -7.4150e-01,  2.1579e-12,\n",
            "         -1.2275e-22, -7.3408e-01, -6.9047e-01, -7.5911e-01,  7.6152e-01,\n",
            "          1.2092e-01, -4.4404e-04, -7.6159e-01,  7.7039e-04, -6.3171e-01,\n",
            "         -7.6153e-01,  2.2033e-10, -2.4251e-02, -5.6090e-01, -1.9615e-09]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  5 torch.Size([1, 100]) tensor([[ 5.9980e-09,  7.9941e-01,  4.0634e-01,  6.8873e-01,  7.6197e-01,\n",
            "         -3.2066e-02, -7.5378e-01,  1.2219e-02, -2.5944e-01,  1.0340e-10,\n",
            "         -3.7411e-03, -7.6754e-01, -3.3059e-15, -4.6459e-01,  2.2059e-01,\n",
            "         -7.5748e-01,  7.3148e-01, -4.0084e-01,  4.7070e-06,  6.8948e-03,\n",
            "         -5.0297e-11, -7.1713e-01,  6.3963e-12, -3.7841e-01, -1.9066e-03,\n",
            "          8.4851e-01, -6.9261e-01,  7.4594e-01,  2.2130e-03, -6.4051e-04,\n",
            "         -4.4392e-17, -3.0323e-06,  9.8235e-14,  6.6511e-10,  7.1866e-01,\n",
            "          4.7288e-22, -3.3359e-08,  7.5773e-01,  7.0085e-13, -7.5757e-01,\n",
            "         -7.6145e-01, -1.6783e-01,  1.0961e-01, -7.6163e-01, -2.0335e-13,\n",
            "          4.6018e-01,  8.5462e-01,  2.5618e-03, -5.0555e-01, -7.6151e-01,\n",
            "          7.6397e-01, -7.4599e-01,  2.5918e-03,  1.3156e-06,  5.5660e-08,\n",
            "         -7.7602e-02, -8.8822e-02,  7.6037e-05,  7.4188e-01, -3.6506e-01,\n",
            "         -7.6148e-01,  4.1366e-01, -4.2641e-08, -7.6159e-01,  2.9654e-08,\n",
            "         -2.5193e-01,  4.8633e-02, -2.5041e-18, -2.0362e-05, -3.7247e-01,\n",
            "          9.7037e-05, -1.5445e-07,  1.7906e-01,  1.4757e-10,  7.5933e-01,\n",
            "          2.0081e-07, -1.3774e-05, -3.5020e-10, -9.5545e-18,  7.6102e-01,\n",
            "         -2.0274e-01, -7.0266e-01, -7.5393e-01, -9.4711e-01, -2.6776e-02,\n",
            "         -7.4680e-01, -3.4732e-05,  1.2982e-07, -5.6420e-03, -1.0155e-07,\n",
            "         -1.3658e-01, -7.6597e-01, -2.8959e-02, -7.6106e-01,  3.7770e-03,\n",
            "         -1.8788e-03,  7.6165e-01, -4.1565e-14, -7.6467e-01,  7.6096e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  6 torch.Size([1, 100]) tensor([[ 1.2493e-06,  9.4941e-01,  9.0397e-01,  9.0898e-04,  7.6386e-01,\n",
            "         -2.3822e-03, -5.9617e-01,  7.6672e-01, -1.6944e-03, -3.2545e-08,\n",
            "         -7.6334e-01,  2.1330e-07,  6.6335e-18, -1.1008e-02,  2.3821e-03,\n",
            "         -3.6441e-06,  2.2229e-01, -7.6147e-01,  9.6007e-01,  2.5790e-01,\n",
            "         -7.5980e-01, -3.0986e-01, -3.3329e-06, -2.6158e-07, -7.6226e-01,\n",
            "          8.4527e-01, -9.5165e-01,  7.5542e-01,  8.3321e-05,  6.7346e-01,\n",
            "         -3.2407e-13, -5.6766e-08,  3.6428e-08,  9.5911e-09,  2.4399e-05,\n",
            "         -5.9830e-17, -5.0385e-04,  9.6338e-01,  7.6069e-01, -1.0453e-05,\n",
            "          3.5871e-01, -7.1526e-01,  1.1898e-04, -2.1504e-03,  1.4422e-14,\n",
            "          7.9104e-06,  3.1819e-08,  5.0196e-23, -7.6224e-01, -9.6377e-01,\n",
            "          7.6287e-01, -8.3918e-01,  1.2820e-01,  1.6965e-01,  1.7065e-07,\n",
            "         -1.4752e-05, -6.7316e-01, -1.5707e-02,  3.7381e-07, -9.0866e-04,\n",
            "         -9.6248e-01, -2.6127e-05, -3.3771e-01, -8.1401e-06, -7.5785e-05,\n",
            "          5.6183e-04,  3.5498e-02,  1.0396e-08, -3.1119e-08, -7.9404e-01,\n",
            "         -7.6130e-01, -2.4450e-10,  1.5925e-01,  9.6010e-05,  9.2556e-01,\n",
            "          2.3269e-06, -8.8795e-05,  7.3860e-01, -1.0600e-21,  2.3130e-02,\n",
            "         -2.8455e-12, -3.1157e-04, -9.6274e-01, -9.3862e-01, -3.7736e-06,\n",
            "         -9.6388e-01, -2.7418e-06,  3.6750e-07, -4.1439e-03, -9.6659e-05,\n",
            "          4.2776e-04, -1.0319e-15,  1.5079e-01, -1.0553e-03,  1.2980e-04,\n",
            "         -3.6853e-11,  4.1908e-05, -1.0720e-11, -9.5090e-01,  2.2810e-02]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  7 torch.Size([1, 100]) tensor([[ 2.1228e-07,  1.8255e-05,  1.2403e-03,  8.4726e-04,  6.9375e-01,\n",
            "         -1.7444e-10,  1.6749e-01,  9.0284e-01, -6.9663e-05, -2.1726e-01,\n",
            "         -5.3572e-01,  4.9643e-02,  1.0766e-10, -3.2503e-02,  6.9127e-08,\n",
            "          3.5291e-06,  9.9446e-01, -1.1292e-15,  1.1328e-03,  9.5942e-01,\n",
            "         -2.9589e-03, -9.7121e-01, -2.3488e-04, -7.5368e-01, -2.1573e-07,\n",
            "          3.4684e-01, -9.8909e-01,  7.0906e-04, -2.9299e-01,  1.3754e-04,\n",
            "          8.7649e-04, -7.5107e-01,  1.8109e-05, -7.6092e-01,  9.2795e-12,\n",
            "         -5.0234e-15, -9.3373e-01,  9.9496e-01,  2.9680e-11, -9.5992e-01,\n",
            "          7.1384e-01, -1.6724e-02,  1.9527e-03, -2.3951e-10,  6.3716e-19,\n",
            "          7.4176e-02,  7.5201e-01,  1.2798e-21, -8.1792e-01, -9.9497e-01,\n",
            "          2.5954e-06, -7.9819e-01,  7.7138e-01,  2.2584e-01,  5.0064e-05,\n",
            "          4.6959e-01, -7.5241e-09, -2.2605e-09,  2.4359e-14,  3.0771e-02,\n",
            "         -9.9391e-01, -7.1339e-01, -8.4408e-01, -2.1710e-01, -9.8829e-08,\n",
            "          1.0160e-07, -2.5297e-04,  3.3536e-05,  7.5474e-01, -9.5811e-01,\n",
            "         -9.5161e-01, -1.5349e-10,  7.6157e-01,  5.5606e-05,  1.4655e-16,\n",
            "          1.7248e-01, -7.6281e-01, -2.8639e-02,  3.0254e-21, -5.1376e-09,\n",
            "         -4.1943e-06, -2.3039e-01, -9.9083e-01, -9.3117e-01, -1.9358e-08,\n",
            "         -9.5061e-01, -8.7907e-19,  3.7431e-01, -8.3931e-11, -9.6195e-14,\n",
            "          6.9053e-01, -6.2646e-01, -8.7766e-14, -3.8785e-06,  5.0601e-08,\n",
            "         -3.8648e-05,  8.5808e-03,  5.1045e-11, -4.5540e-01,  1.9807e-03]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  8 torch.Size([1, 100]) tensor([[ 4.9234e-04,  0.0000e+00,  7.6161e-01,  7.0551e-15,  7.6170e-01,\n",
            "         -9.5663e-01,  8.3233e-01,  9.9429e-01, -3.5914e-01, -8.3988e-01,\n",
            "         -2.2928e-05,  6.2369e-22,  0.0000e+00, -3.6954e-21,  7.5351e-01,\n",
            "          1.1548e-36,  9.9925e-01, -0.0000e+00,  0.0000e+00,  9.9441e-01,\n",
            "         -9.1085e-01, -2.3802e-10, -6.7047e-01, -7.5939e-01, -1.1528e-26,\n",
            "          1.9762e-05, -7.4220e-03,  7.6159e-01, -9.6348e-01,  1.5781e-28,\n",
            "          2.0233e-11, -9.6225e-01,  2.4868e-13, -9.6403e-01,  0.0000e+00,\n",
            "         -1.0390e-19, -9.9171e-01,  7.6159e-01,  3.6663e-02, -9.9450e-01,\n",
            "          7.6131e-01, -7.3667e-31,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "          7.6607e-01,  9.6390e-01,  7.0065e-45, -9.7329e-01, -9.9932e-01,\n",
            "          9.6307e-34, -9.6351e-01,  9.6567e-01,  2.1700e-25,  9.6400e-01,\n",
            "          9.0686e-01, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -4.7727e-01, -1.5689e-31, -9.7737e-01, -9.6408e-01, -1.8616e-40,\n",
            "          2.7515e-13, -0.0000e+00,  7.9319e-05,  7.6159e-01, -9.9423e-01,\n",
            "         -9.9331e-01, -4.3105e-14,  2.4202e-19,  1.7479e-05,  1.9669e-23,\n",
            "          8.3928e-01, -9.6463e-01, -7.6159e-01,  7.7889e-40, -8.8060e-22,\n",
            "         -2.5254e-29,  5.3716e-01, -9.9923e-01,  4.3704e-01, -1.8272e-33,\n",
            "         -9.9932e-01,  8.3039e-35,  1.1585e-14, -1.0132e-08, -0.0000e+00,\n",
            "          9.5146e-01, -7.6159e-01, -6.5191e-03, -7.6236e-01,  6.4405e-01,\n",
            "         -1.2790e-16,  4.2391e-11,  5.1859e-10,  1.5824e-01,  5.0026e-43]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  9 torch.Size([1, 100]) tensor([[ 7.6477e-01,  7.5993e-01,  5.9095e-03,  2.8204e-04,  6.2366e-05,\n",
            "         -9.9386e-01,  6.2494e-10,  3.2125e-02, -1.5831e-01, -6.5487e-01,\n",
            "         -2.8663e-01,  4.4130e-29,  2.0942e-03, -7.6412e-01,  6.8161e-05,\n",
            "          7.6139e-01,  9.9990e-01, -1.8104e-26,  5.1380e-02,  1.7247e-03,\n",
            "         -2.1640e-02, -2.2828e-08, -2.8923e-01, -7.6159e-01, -5.1044e-19,\n",
            "          4.3363e-12, -7.6280e-01,  9.6402e-01, -9.9489e-01,  2.1007e-03,\n",
            "          6.8787e-03, -5.9561e-05,  7.6159e-01, -9.6655e-01,  4.9028e-09,\n",
            "         -7.0198e-01, -9.9887e-01,  7.6158e-01,  1.5247e-12, -8.9210e-01,\n",
            "          2.3534e-02, -2.7494e-03,  1.6696e-12, -3.5817e-18,  1.0648e-14,\n",
            "          5.5433e-09,  9.9479e-01,  8.5768e-03, -5.6302e-01, -5.4655e-02,\n",
            "          5.8908e-01, -2.7064e-02,  8.6630e-01,  7.6159e-01,  9.0424e-01,\n",
            "          9.6168e-01, -9.3724e-10, -7.9700e-07,  1.0237e-06,  7.5453e-01,\n",
            "         -1.0425e-01, -6.5461e-01, -9.9678e-01, -9.9504e-01, -7.5334e-12,\n",
            "          9.5748e-11, -7.6146e-01, -1.1788e-22,  8.5313e-01, -3.7303e-01,\n",
            "         -9.9327e-01, -6.6927e-01,  4.5087e-01,  7.6142e-01,  7.6159e-01,\n",
            "          2.6397e-04, -2.6727e-07, -9.6315e-01, -1.7741e-06, -5.5042e-11,\n",
            "         -5.0392e-01,  8.0990e-01, -1.3828e-03,  4.8792e-09, -4.4468e-10,\n",
            "         -2.2872e-02,  7.5360e-01,  7.6159e-01, -4.3304e-10,  3.0645e-04,\n",
            "          7.4184e-01, -7.6540e-10, -7.8502e-09, -7.5513e-01,  1.1360e-04,\n",
            "         -4.2047e-02,  1.1333e-09,  7.4752e-01,  1.8939e-07,  4.1450e-02]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  10 torch.Size([1, 100]) tensor([[ 4.7378e-06,  6.2285e-02, -1.0811e-05,  9.2338e-05,  5.2997e-05,\n",
            "         -1.3214e-01,  1.8732e-01,  3.9513e-21, -3.4950e-01, -4.6426e-02,\n",
            "         -7.4503e-01, -1.3583e-01, -2.1294e-08, -3.4815e-03, -2.6036e-03,\n",
            "         -7.3991e-01, -6.0509e-06,  5.5169e-04, -6.3525e-15,  6.0846e-01,\n",
            "          4.1312e-01,  1.9645e-20, -9.3258e-01,  1.3179e-03,  2.0099e-23,\n",
            "         -7.5973e-01,  4.1700e-03,  6.7763e-07, -9.6316e-01, -3.6858e-01,\n",
            "         -3.2273e-06, -8.5493e-01, -5.4836e-06, -6.5773e-02, -2.6171e-07,\n",
            "          1.1798e-01, -9.9946e-01, -2.3013e-11,  1.2694e-06, -9.9450e-01,\n",
            "         -7.3350e-11,  9.7987e-06,  7.9636e-04,  4.7501e-01, -7.6159e-01,\n",
            "         -4.1684e-01,  9.6228e-01, -7.4918e-01, -9.7138e-01,  2.0240e-01,\n",
            "          2.4517e-01,  4.0570e-10,  5.1985e-01, -4.4894e-01,  4.5820e-01,\n",
            "          7.4776e-01, -1.3913e-05,  7.3641e-01, -7.6137e-01,  7.7204e-08,\n",
            "          9.1128e-15, -3.7469e-12,  4.3224e-11,  9.5523e-02,  8.9942e-02,\n",
            "         -9.8767e-22, -7.2040e-01, -3.2630e-19,  9.7823e-01, -1.2408e-11,\n",
            "         -8.8321e-01, -3.6399e-19,  5.4974e-01,  8.2254e-06,  7.5205e-01,\n",
            "         -7.3182e-01, -2.6943e-10, -7.5974e-01,  7.6102e-01,  1.3726e-22,\n",
            "          3.2979e-01, -2.1833e-01, -1.8239e-23, -4.1946e-07,  7.6144e-01,\n",
            "         -9.6328e-08, -7.2221e-12,  2.6660e-03,  2.2115e-02,  9.6148e-01,\n",
            "          1.7821e-04, -7.8081e-05, -7.3165e-01,  1.5196e-02, -4.4962e-01,\n",
            "          7.4335e-01, -4.1291e-05,  1.5979e-01, -4.4733e-28, -2.5489e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  11 torch.Size([1, 100]) tensor([[ 7.6358e-01,  1.5002e-28, -2.6161e-02,  1.5777e-24,  3.6001e-09,\n",
            "         -1.7386e-10,  8.3264e-01,  5.1824e-07, -8.7752e-01, -6.1861e-01,\n",
            "         -3.5728e-05, -3.1571e-05,  1.6228e-06, -2.6992e-09, -1.3888e-15,\n",
            "          3.0563e-18,  7.1228e-01, -8.9920e-19,  1.9389e-31,  9.9924e-01,\n",
            "          9.0087e-01, -1.5506e-13, -9.9428e-01, -7.6104e-01, -7.7975e-30,\n",
            "         -2.0662e-06, -2.5011e-10,  9.3850e-07, -9.9491e-01,  8.5834e-11,\n",
            "          7.4030e-01, -9.7905e-01,  7.6159e-01, -8.6157e-01,  1.9642e-28,\n",
            "         -7.0706e-01, -9.9993e-01,  1.8411e-16,  7.6161e-01, -9.9925e-01,\n",
            "          7.5949e-01, -6.4326e-29,  1.1905e-15, -4.3387e-22,  7.3208e-01,\n",
            "          5.0043e-01,  9.9481e-01,  8.2282e-04, -9.9627e-01,  8.2539e-03,\n",
            "          1.1745e-12, -4.6382e-15,  9.1800e-01, -7.2208e-11,  9.0400e-01,\n",
            "          9.6166e-01, -4.0690e-28, -6.6614e-04,  1.2268e-19,  5.1034e-14,\n",
            "         -5.0073e-24, -7.7418e-03,  1.8236e-03, -7.1833e-01,  1.3478e-06,\n",
            "          6.3507e-15, -1.9150e-19, -7.6159e-01,  9.9697e-01, -9.0452e-01,\n",
            "         -8.9670e-01, -7.4868e-01,  1.9380e-09,  7.6159e-01,  2.1740e-13,\n",
            "          6.7255e-02, -4.1324e-14, -9.6371e-01,  8.1717e-02, -1.0718e-16,\n",
            "         -5.7664e-01, -2.1784e-01, -1.0455e-23,  2.0214e-05, -1.9442e-10,\n",
            "         -1.8876e-24,  7.2900e-11,  7.6263e-01, -2.7444e-01,  4.3647e-08,\n",
            "         -8.7560e-04, -7.6163e-01,  6.1253e-01, -7.5514e-01,  4.7443e-01,\n",
            "          9.3517e-01, -1.5730e-14,  8.2142e-01,  3.9941e-15,  5.2004e-22]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "encdr word  12 torch.Size([1, 100]) tensor([[ 9.1971e-01,  2.1970e-11,  7.6159e-01,  1.0273e-26,  1.5581e-19,\n",
            "         -6.3786e-04,  9.7558e-01,  1.0417e-22, -9.8250e-01, -9.3547e-01,\n",
            "         -1.1735e-05, -3.2746e-23,  9.3184e-01,  6.3939e-07,  4.8740e-05,\n",
            "          3.6648e-03, -1.0812e-01, -2.0001e-08,  1.2247e-19,  6.6258e-01,\n",
            "          4.4368e-01, -8.9546e-10, -2.7539e-01, -7.6159e-01, -1.4089e-19,\n",
            "          1.5432e-03, -4.1860e-11,  7.0838e-01, -9.6299e-01, -1.0093e-05,\n",
            "          3.3137e-01, -9.9709e-01,  9.6402e-01, -8.4615e-01,  1.3913e-10,\n",
            "         -7.6160e-01, -9.9999e-01,  5.9265e-10,  9.4868e-01, -9.9990e-01,\n",
            "          4.6906e-20,  2.4371e-12,  5.5701e-16, -5.1848e-44,  5.9729e-01,\n",
            "          9.0873e-01,  8.1214e-06,  1.2613e-04, -9.9950e-01,  8.5818e-19,\n",
            "          5.6260e-02, -1.6251e-16,  9.8849e-01,  7.6159e-01,  9.8645e-01,\n",
            "          9.9472e-01, -1.6823e-03, -7.6159e-01,  7.6145e-01,  1.7297e-15,\n",
            "         -6.7718e-21, -6.6359e-03, -7.6150e-01, -9.5650e-01, -7.6159e-01,\n",
            "          3.4115e-17, -6.5659e-06, -1.7673e-01,  9.9960e-01, -9.0157e-01,\n",
            "         -3.9262e-07, -1.1240e-02,  4.7270e-29,  9.6403e-01,  7.6160e-01,\n",
            "          7.8846e-01, -1.1716e-17, -7.6158e-01, -6.7445e-03, -4.2374e-13,\n",
            "         -9.2986e-01,  6.5191e-01, -3.6872e-22,  7.6154e-01, -4.1422e-41,\n",
            "         -2.0702e-22,  4.4698e-21,  9.6420e-01, -1.4401e-12,  5.2841e-01,\n",
            "          3.3062e-11, -4.9831e-02,  6.2883e-01, -9.6294e-01,  8.5877e-01,\n",
            "          9.8988e-01, -2.1695e-04,  9.7374e-01,  3.0410e-04,  3.8816e-08]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  0 torch.Size([1, 100]) tensor([[-7.6236e-01,  5.9335e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          7.9389e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -6.5270e-01,  0.0000e+00,  4.1753e-27,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -6.7392e-34, -8.2695e-01,  0.0000e+00,\n",
            "          0.0000e+00,  1.3788e-29,  7.1248e-01,  9.3335e-28, -0.0000e+00,\n",
            "          7.1901e-01,  8.2039e-01,  8.3028e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -8.1641e-01, -6.4364e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -8.1782e-01,  0.0000e+00, -7.1628e-01, -7.3034e-01,  0.0000e+00,\n",
            "          8.1401e-01,  5.9979e-02, -0.0000e+00,  0.0000e+00, -7.0680e-01,\n",
            "          0.0000e+00,  7.4117e-01,  8.3946e-01,  2.4540e-33,  7.1385e-01,\n",
            "         -7.7255e-01, -0.0000e+00,  8.3581e-01, -3.9675e-33,  0.0000e+00,\n",
            "         -7.9821e-01,  0.0000e+00,  0.0000e+00,  7.3083e-01,  0.0000e+00,\n",
            "         -6.5694e-01,  2.2421e-44, -0.0000e+00, -7.9935e-01,  0.0000e+00,\n",
            "         -8.0656e-01,  7.8981e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -7.7822e-01,  2.3191e-25, -0.0000e+00, -0.0000e+00,  7.6702e-01,\n",
            "         -7.6160e-01,  3.1937e-34,  0.0000e+00, -7.8599e-01,  7.9865e-01,\n",
            "          7.9916e-01, -0.0000e+00,  0.0000e+00,  8.1559e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  6.6845e-01,  6.1993e-01,  0.0000e+00,\n",
            "          7.6435e-01, -0.0000e+00,  7.7706e-01, -0.0000e+00,  1.4679e-16,\n",
            "         -7.4899e-01,  7.1630e-01,  7.6568e-01,  2.3327e-35,  7.4438e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  1 torch.Size([1, 100]) tensor([[-9.6416e-01,  9.3323e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.6938e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.4469e-01,  0.0000e+00,  8.1275e-44,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.7469e-01,  0.0000e+00,\n",
            "          0.0000e+00,  1.7691e-41,  9.5557e-01,  4.6596e-37, -0.0000e+00,\n",
            "          9.5671e-01,  9.7365e-01,  9.7521e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -9.7301e-01, -9.4299e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.7324e-01,  0.0000e+00, -9.5623e-01, -9.5869e-01,  0.0000e+00,\n",
            "          9.7263e-01,  6.0000e-02, -0.0000e+00,  0.0000e+00, -9.5456e-01,\n",
            "          0.0000e+00,  9.6056e-01,  9.7665e-01,  0.0000e+00,  9.5581e-01,\n",
            "         -9.6586e-01, -0.0000e+00,  9.7608e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.7008e-01,  0.0000e+00,  0.0000e+00,  9.5877e-01,  0.0000e+00,\n",
            "         -9.4549e-01,  0.0000e+00, -0.0000e+00, -9.7027e-01,  0.0000e+00,\n",
            "         -9.7001e-01,  9.6871e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.6680e-01,  1.0650e-43, -0.0000e+00, -0.0000e+00,  9.6494e-01,\n",
            "         -7.6160e-01,  2.9141e-37,  0.0000e+00, -9.6808e-01,  9.7015e-01,\n",
            "          9.7023e-01, -0.0000e+00,  0.0000e+00,  9.7288e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.4762e-01,  9.3845e-01,  0.0000e+00,\n",
            "          9.6449e-01, -0.0000e+00,  9.6661e-01, -0.0000e+00,  1.0070e-30,\n",
            "         -9.6189e-01,  9.5624e-01,  9.6471e-01,  9.0136e-40,  9.6111e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  2 torch.Size([1, 100]) tensor([[-9.9507e-01,  9.9069e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9580e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9233e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9654e-01,  0.0000e+00,\n",
            "          0.0000e+00,  2.8026e-45,  9.9387e-01,  1.0250e-38, -0.0000e+00,\n",
            "          9.9403e-01,  9.9639e-01,  9.9661e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -9.9630e-01, -9.9209e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9634e-01,  0.0000e+00, -9.9396e-01, -9.9431e-01,  0.0000e+00,\n",
            "          9.9625e-01,  6.0000e-02, -0.0000e+00,  0.0000e+00, -9.9373e-01,\n",
            "          0.0000e+00,  9.9457e-01,  9.9681e-01,  0.0000e+00,  9.9390e-01,\n",
            "         -9.9531e-01, -0.0000e+00,  9.9673e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9590e-01,  0.0000e+00,  0.0000e+00,  9.9432e-01,  0.0000e+00,\n",
            "         -9.9244e-01,  0.0000e+00, -0.0000e+00, -9.9592e-01,  0.0000e+00,\n",
            "         -9.9479e-01,  9.9571e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9544e-01,  0.0000e+00, -0.0000e+00, -0.0000e+00,  9.9518e-01,\n",
            "         -7.6159e-01,  8.9384e-38,  0.0000e+00, -9.9562e-01,  9.9591e-01,\n",
            "          9.9592e-01, -0.0000e+00,  0.0000e+00,  9.9629e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9275e-01,  9.9144e-01,  0.0000e+00,\n",
            "          9.9512e-01, -0.0000e+00,  9.9542e-01, -0.0000e+00,  7.9109e-41,\n",
            "         -9.9476e-01,  9.9396e-01,  9.9515e-01,  6.4446e-42,  9.9465e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  3 torch.Size([1, 100]) tensor([[-9.9933e-01,  9.9874e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9943e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9896e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9953e-01,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.9917e-01,  5.7902e-39, -0.0000e+00,\n",
            "          9.9919e-01,  9.9951e-01,  9.9954e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -9.9950e-01, -9.9893e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9950e-01,  0.0000e+00, -9.9918e-01, -9.9923e-01,  0.0000e+00,\n",
            "          9.9949e-01,  6.0000e-02, -0.0000e+00,  0.0000e+00, -9.9915e-01,\n",
            "          0.0000e+00,  9.9926e-01,  9.9957e-01,  0.0000e+00,  9.9917e-01,\n",
            "         -9.9936e-01, -0.0000e+00,  9.9956e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9944e-01,  0.0000e+00,  0.0000e+00,  9.9923e-01,  0.0000e+00,\n",
            "         -9.9897e-01,  0.0000e+00, -0.0000e+00, -9.9945e-01,  0.0000e+00,\n",
            "         -9.9869e-01,  9.9942e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9938e-01,  0.0000e+00, -0.0000e+00, -0.0000e+00,  9.9935e-01,\n",
            "         -7.6159e-01,  7.4057e-38,  0.0000e+00, -9.9941e-01,  9.9945e-01,\n",
            "          9.9945e-01, -0.0000e+00,  0.0000e+00,  9.9950e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9902e-01,  9.9884e-01,  0.0000e+00,\n",
            "          9.9934e-01, -0.0000e+00,  9.9938e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9929e-01,  9.9918e-01,  9.9934e-01,  2.9848e-42,  9.9927e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  4 torch.Size([1, 100]) tensor([[-9.9991e-01,  9.9983e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9992e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9986e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9994e-01,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.9989e-01,  5.3474e-39, -0.0000e+00,\n",
            "          9.9989e-01,  9.9993e-01,  9.9994e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -9.9993e-01, -9.9985e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9993e-01,  0.0000e+00, -9.9989e-01, -9.9990e-01,  0.0000e+00,\n",
            "          9.9993e-01,  6.0000e-02, -0.0000e+00,  0.0000e+00, -9.9988e-01,\n",
            "          0.0000e+00,  9.9990e-01,  9.9994e-01,  0.0000e+00,  9.9989e-01,\n",
            "         -9.9991e-01, -0.0000e+00,  9.9994e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9992e-01,  0.0000e+00,  0.0000e+00,  9.9990e-01,  0.0000e+00,\n",
            "         -9.9986e-01,  0.0000e+00, -0.0000e+00, -9.9993e-01,  0.0000e+00,\n",
            "         -9.9932e-01,  9.9992e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9992e-01,  0.0000e+00, -0.0000e+00, -0.0000e+00,  9.9991e-01,\n",
            "         -7.6159e-01,  7.2107e-38,  0.0000e+00, -9.9992e-01,  9.9992e-01,\n",
            "          9.9993e-01, -0.0000e+00,  0.0000e+00,  9.9993e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9987e-01,  9.9984e-01,  0.0000e+00,\n",
            "          9.9991e-01, -0.0000e+00,  9.9992e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9990e-01,  9.9989e-01,  9.9991e-01,  2.6807e-42,  9.9990e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  5 torch.Size([1, 100]) tensor([[-9.9999e-01,  9.9998e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          9.9999e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9998e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -9.9999e-01,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.9998e-01,  5.2887e-39, -0.0000e+00,\n",
            "          9.9999e-01,  9.9999e-01,  9.9999e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -9.9999e-01, -9.9998e-01,  0.0000e+00, -0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00, -9.9998e-01, -9.9999e-01,  0.0000e+00,\n",
            "          9.9999e-01,  6.0000e-02, -0.0000e+00,  0.0000e+00, -9.9998e-01,\n",
            "          0.0000e+00,  9.9999e-01,  9.9999e-01,  0.0000e+00,  9.9998e-01,\n",
            "         -9.9999e-01, -0.0000e+00,  9.9999e-01,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00,  0.0000e+00,  9.9999e-01,  0.0000e+00,\n",
            "         -9.9998e-01,  0.0000e+00, -0.0000e+00, -9.9999e-01,  0.0000e+00,\n",
            "         -9.9943e-01,  9.9999e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  0.0000e+00, -0.0000e+00, -0.0000e+00,  9.9999e-01,\n",
            "         -7.6159e-01,  7.1837e-38,  0.0000e+00, -9.9999e-01,  9.9999e-01,\n",
            "          9.9999e-01, -0.0000e+00,  0.0000e+00,  9.9999e-01, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  9.9998e-01,  9.9998e-01,  0.0000e+00,\n",
            "          9.9999e-01, -0.0000e+00,  9.9999e-01, -0.0000e+00,  0.0000e+00,\n",
            "         -9.9999e-01,  9.9998e-01,  9.9999e-01,  2.6400e-42,  9.9999e-01]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  6 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2805e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9944e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1798e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6358e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  7 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2794e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1793e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  8 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2792e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1791e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  9 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2792e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1791e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  10 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2792e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1791e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  11 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2792e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1791e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n",
            "decd word  12 torch.Size([1, 100]) tensor([[-1.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.0000e+00,  5.2792e-39, -0.0000e+00,\n",
            "          1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00, -0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -1.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  6.0000e-02, -0.0000e+00,  0.0000e+00, -1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "         -1.0000e+00, -0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
            "         -9.9945e-01,  1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0000e+00,\n",
            "         -7.6159e-01,  7.1791e-38,  0.0000e+00, -1.0000e+00,  1.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  0.0000e+00,  1.0000e+00, -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00, -0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+00,  1.0000e+00,  1.0000e+00,  2.6344e-42,  1.0000e+00]],\n",
            "       device='cuda:0', grad_fn=<ThnnFusedLstmCellBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HwjrPw0W-qu"
      },
      "source": [
        "## Testing the model on 10 random review comments from the validation set to predict the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBCajTM636dI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aa76b66-cbec-415a-9864-2fa2c1f7dba5"
      },
      "source": [
        "import random \n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "TESTSAMPLE = 10\n",
        "\n",
        "validindex = np.arange (len(valid))\n",
        "\n",
        "printEncoderDecoderOutput = False\n",
        "randindex = random.choices(validindex , k=10)\n",
        "\n",
        "sentenceLabelPrediction = []\n",
        "\n",
        "for i in range(TESTSAMPLE)  :\n",
        "  slp = {}\n",
        "  out = vars(valid.examples[randindex[i]])\n",
        "  \n",
        "  true_label = categories[out['label']]\n",
        "  in_tweet = ' '.join(out['tweet'])\n",
        "  pred_label = classify_tweet(in_tweet)\n",
        "\n",
        "  strTruelabel = 'True label: ' + str(true_label)\n",
        "  strPredlabel = 'Predicted label: ' +  str(pred_label)\n",
        "  strSentence =  'Input Sentence: ' + in_tweet\n",
        "  slp['Truelabel'] = true_label\n",
        "  slp['Predictedlabel'] = pred_label\n",
        "  slp['Input Sentence'] = in_tweet\n",
        "\n",
        "  sentenceLabelPrediction.append(slp)\n",
        "  \n",
        "  lineSeparator = '---------------------------------'\n",
        "  display(Markdown('<strong>{}</strong><br><br><strong>{}</strong><br><br>{}<br><br><strong>{}</strong><br><br>'.format(strTruelabel , strPredlabel , strSentence , lineSeparator)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: BUM ! Obama \" threatens \" supreme court justices considering repealing his unconstitutional healthcare law . Nice move bum !<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: @ericbolling # Hillary 's gon na challenge # Obama<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @ohgirlphrase : American kid \" You 're from the UK ? Ohhh cool , So do you have tea with the Queen ? \" . British kid : \" Do you like , go to Mcdonalds with Obama ?<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: @AC360   President Obama is a Constitutional Law scholar - give him credit and the respect that he deserves .   @JaySekulow is annoying .<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Positive</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: Obama signs JOBS Act to boost startup firms - http://t.co/TFuPTCwT<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @ohgirlphrase : American kid \" You 're from the UK ? Ohhh cool , So do you have tea with the Queen ? \" . British kid : \" Do you like , go to Mcdonalds with Obama ?<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: It 's incredible that something like # WhatsRomneyHiding would be trending . Yet Obama is sneakiest , harmful person and no one says anything .<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: A \" legislator \" who 'd never passed legislation . A \" law professor \" who 'd never published a law review article ... Is Obama fictional ? # hhrs<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: RT @anna12061 : Another Obama Buddy !<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "<strong>True label: Negative</strong><br><br><strong>Predicted label: Negative</strong><br><br>Input Sentence: @obama start tweeting dang<br><br><strong>---------------------------------</strong><br><br>",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpzwfiJu0H9"
      },
      "source": [
        "### store the information for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyueHFvP4Yoi"
      },
      "source": [
        "diagnosticDict = {}\n",
        "\n",
        "diagnosticDict['num_hidden_nodes'] = num_hidden_nodes\n",
        "diagnosticDict['epochs'] = N_EPOCHS\n",
        "diagnosticDict['lr'] = learning_rate\n",
        "diagnosticDict['batchsize'] = batch_size\n",
        "diagnosticDict['trainLossList'] = trainLossList\n",
        "diagnosticDict['valLossList']= valLossList\n",
        "diagnosticDict['trainAccyList'] = trainAccyList\n",
        "diagnosticDict['valAccyList'] = valAccyList\n",
        "diagnosticDict['sentencelabelpredict'] = sentenceLabelPrediction\n",
        "\n",
        "#diagnosticDict"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBpGdtqf4iFA"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"encdr_dcdr_lstmdiagnostic.json\", \"a\") as out_file:\n",
        "  json.dump(diagnosticDict, out_file, indent = 6)\n"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}